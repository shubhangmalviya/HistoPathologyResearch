{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Research Question 3: Complete GPU-Accelerated Pipeline\n",
        "## Stain Normalization Impact on U-Net Nuclei Segmentation\n",
        "\n",
        "**Research Question**: Does stain normalization improve U-Net-based nuclei instance segmentation on the PanNuke dataset compared to unnormalized data?\n",
        "\n",
        "### Hypotheses:\n",
        "- **H‚ÇÄ (Null)**: No significant improvement due to normalization  \n",
        "- **H‚ÇÅ (Alternative)**: Significant improvement due to normalization\n",
        "\n",
        "### Methodology:\n",
        "1. **Dataset**: Top 5 tissues from PanNuke dataset\n",
        "2. **Normalization**: Vahadane method with GPU acceleration\n",
        "3. **Models**: U-Net trained on normalized vs unnormalized data\n",
        "4. **Evaluation**: Paired statistical analysis per image\n",
        "5. **Statistics**: Wilcoxon signed-rank test, paired t-test\n",
        "\n",
        "### Expected Outcomes:\n",
        "- Comprehensive EDA before/after normalization\n",
        "- Model performance comparison\n",
        "- Statistical significance testing\n",
        "- Complete artifacts for reproducibility\n",
        "\n",
        "---\n",
        "**‚ö° GPU-Accelerated Pipeline | Production Ready | Cloud Deployment**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# IMPORTS AND SETUP\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import jaccard_score, f1_score, precision_score, recall_score\n",
        "from scipy.stats import wilcoxon, ttest_rel\n",
        "import logging\n",
        "\n",
        "# Setup paths\n",
        "project_root = Path('/Users/shubhangmalviya/Documents/Projects/Walsh College/HistoPathologyResearch')\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Import custom modules\n",
        "from src.preprocessing.vahadane_gpu import GPUVahadaneNormalizer\n",
        "from src.models.unet_rq3 import UNetRQ3, create_unet_rq3  # RQ3-specific U-Net (separate from RQ2)\n",
        "from src.utils.metrics import calculate_segmentation_metrics\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('artifacts/rq3/logs/rq3_pipeline.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set style and warnings\n",
        "plt.style.use('seaborn-v0_8') if 'seaborn-v0_8' in plt.style.available else plt.style.use('seaborn')\n",
        "sns.set_palette('husl')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üöÄ RQ3 Pipeline initialized on {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Create artifacts directories\n",
        "artifacts_dir = project_root / 'artifacts' / 'rq3'\n",
        "for subdir in ['checkpoints', 'results', 'datasets', 'plots', 'logs']:\n",
        "    (artifacts_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "logger.info(\"RQ3 Complete Pipeline - GPU Accelerated - Initialized Successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Analysis and Preparation\n",
        "\n",
        "### 1.1 Identify Top 5 Tissues by Sample Count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DATASET ANALYSIS - TOP 5 TISSUES\n",
        "# =============================================================================\n",
        "\n",
        "dataset_path = project_root / 'dataset_tissues'\n",
        "logger.info(\"Analyzing dataset to identify top 5 tissues...\")\n",
        "\n",
        "# Count images per tissue\n",
        "tissue_counts = {}\n",
        "tissue_paths = {}\n",
        "\n",
        "for tissue_dir in dataset_path.iterdir():\n",
        "    if tissue_dir.is_dir():\n",
        "        tissue_name = tissue_dir.name\n",
        "        total_count = 0\n",
        "        paths = {'train': [], 'test': [], 'val': []}\n",
        "        \n",
        "        for split in ['train', 'test', 'val']:\n",
        "            images_dir = tissue_dir / split / 'images'\n",
        "            masks_dir = tissue_dir / split / 'sem_masks'  # Semantic masks\n",
        "            \n",
        "            if images_dir.exists() and masks_dir.exists():\n",
        "                image_files = list(images_dir.glob('*.png'))\n",
        "                mask_files = list(masks_dir.glob('*.png'))\n",
        "                \n",
        "                # Only count images that have corresponding masks\n",
        "                valid_pairs = []\n",
        "                for img_file in image_files:\n",
        "                    mask_file = masks_dir / img_file.name.replace('img_', 'sem_')\n",
        "                    if mask_file.exists():\n",
        "                        valid_pairs.append((img_file, mask_file))\n",
        "                \n",
        "                paths[split] = valid_pairs\n",
        "                total_count += len(valid_pairs)\n",
        "        \n",
        "        tissue_counts[tissue_name] = total_count\n",
        "        tissue_paths[tissue_name] = paths\n",
        "\n",
        "# Sort tissues by count and select top 5\n",
        "top_5_tissues = sorted(tissue_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "selected_tissues = [tissue for tissue, count in top_5_tissues]\n",
        "\n",
        "print(\"üîç Dataset Analysis Results:\")\n",
        "print(\"=\" * 50)\n",
        "for tissue, count in sorted(tissue_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "    marker = \"‚úÖ\" if tissue in selected_tissues else \"  \"\n",
        "    print(f\"{marker} {tissue:15}: {count:,} images\")\n",
        "\n",
        "print(f\"\\nüéØ Selected Top 5 Tissues for RQ3:\")\n",
        "for i, (tissue, count) in enumerate(top_5_tissues, 1):\n",
        "    print(f\"{i}. {tissue}: {count:,} images\")\n",
        "\n",
        "total_selected = sum(count for _, count in top_5_tissues)\n",
        "print(f\"\\nüìä Total images in top 5 tissues: {total_selected:,}\")\n",
        "\n",
        "# Save tissue selection metadata\n",
        "tissue_metadata = {\n",
        "    'selected_tissues': selected_tissues,\n",
        "    'tissue_counts': dict(top_5_tissues),\n",
        "    'total_images': total_selected,\n",
        "    'selection_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'selection_criteria': 'Top 5 tissues by image count'\n",
        "}\n",
        "\n",
        "with open(artifacts_dir / 'results' / 'tissue_selection.json', 'w') as f:\n",
        "    json.dump(tissue_metadata, f, indent=2)\n",
        "\n",
        "logger.info(f\"Selected {len(selected_tissues)} tissues with {total_selected:,} total images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Create Small Sample for Testing\n",
        "\n",
        "Before processing the full dataset, let's create a small sample to test the pipeline and ensure everything works correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CREATE TEST SAMPLE\n",
        "# =============================================================================\n",
        "\n",
        "# Configuration for testing vs production\n",
        "TESTING_MODE = True  # Set to False for full dataset processing\n",
        "SAMPLE_SIZE_PER_TISSUE = 5 if TESTING_MODE else None  # None means use all images\n",
        "\n",
        "print(f\"üß™ Running in {'TESTING' if TESTING_MODE else 'PRODUCTION'} mode\")\n",
        "if TESTING_MODE:\n",
        "    print(f\"   Sample size: {SAMPLE_SIZE_PER_TISSUE} images per tissue per split\")\n",
        "\n",
        "# Create sample dataset for testing\n",
        "sample_data = {}\n",
        "total_sample_images = 0\n",
        "\n",
        "for tissue in selected_tissues:\n",
        "    sample_data[tissue] = {'train': [], 'test': [], 'val': []}\n",
        "    \n",
        "    for split in ['train', 'test', 'val']:\n",
        "        available_pairs = tissue_paths[tissue][split]\n",
        "        \n",
        "        if TESTING_MODE and SAMPLE_SIZE_PER_TISSUE:\n",
        "            # Take a small sample for testing\n",
        "            selected_pairs = available_pairs[:SAMPLE_SIZE_PER_TISSUE]\n",
        "        else:\n",
        "            # Use all available data\n",
        "            selected_pairs = available_pairs\n",
        "        \n",
        "        sample_data[tissue][split] = selected_pairs\n",
        "        total_sample_images += len(selected_pairs)\n",
        "        \n",
        "        print(f\"üìÅ {tissue:15} {split:5}: {len(selected_pairs):3} images\")\n",
        "\n",
        "print(f\"\\nüìä Total sample images: {total_sample_images:,}\")\n",
        "print(f\"üéØ Expected processing time: {total_sample_images * 0.001 / 60:.1f} minutes (GPU)\")\n",
        "\n",
        "# Save sample configuration\n",
        "sample_config = {\n",
        "    'testing_mode': TESTING_MODE,\n",
        "    'sample_size_per_tissue': SAMPLE_SIZE_PER_TISSUE,\n",
        "    'total_sample_images': total_sample_images,\n",
        "    'tissues': selected_tissues,\n",
        "    'splits': ['train', 'test', 'val']\n",
        "}\n",
        "\n",
        "with open(artifacts_dir / 'results' / 'sample_config.json', 'w') as f:\n",
        "    json.dump(sample_config, f, indent=2)\n",
        "\n",
        "logger.info(f\"Sample configuration created: {total_sample_images} images across {len(selected_tissues)} tissues\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GPU-Accelerated Vahadane Stain Normalization\n",
        "\n",
        "### 2.1 Initialize GPU Normalizer and Select Target Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# GPU VAHADANE STAIN NORMALIZATION SETUP\n",
        "# =============================================================================\n",
        "\n",
        "logger.info(\"Initializing GPU-accelerated Vahadane normalizer...\")\n",
        "\n",
        "# Initialize GPU normalizer with optimal settings\n",
        "gpu_normalizer = GPUVahadaneNormalizer(\n",
        "    batch_size=16,  # Adjust based on GPU memory\n",
        "    device=device,\n",
        "    memory_efficient=True,\n",
        "    threshold=0.8,\n",
        "    lambda1=0.1,\n",
        "    max_iter=1000\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ GPU Vahadane normalizer initialized on {device}\")\n",
        "\n",
        "# Function to evaluate image quality for target selection\n",
        "def evaluate_image_quality_gpu(image_tensor):\n",
        "    \"\"\"Evaluate image quality using GPU-accelerated metrics\"\"\"\n",
        "    if len(image_tensor.shape) == 3:\n",
        "        image_tensor = image_tensor.unsqueeze(0)\n",
        "    \n",
        "    img = image_tensor.float() / 255.0\n",
        "    \n",
        "    # Tissue coverage (non-white pixels)\n",
        "    gray = torch.mean(img, dim=-1)\n",
        "    tissue_mask = gray < 0.8\n",
        "    tissue_coverage = torch.mean(tissue_mask.float())\n",
        "    \n",
        "    # Contrast (standard deviation)\n",
        "    contrast = torch.std(gray)\n",
        "    \n",
        "    # Color distribution\n",
        "    color_std = torch.std(img, dim=(1, 2))\n",
        "    color_balance = torch.mean(color_std)\n",
        "    \n",
        "    # Combined quality score\n",
        "    quality_score = (\n",
        "        tissue_coverage * 40 +\n",
        "        contrast * 30 +\n",
        "        color_balance * 30\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'quality_score': quality_score.item(),\n",
        "        'tissue_coverage': tissue_coverage.item(),\n",
        "        'contrast': contrast.item(),\n",
        "        'color_balance': color_balance.item()\n",
        "    }\n",
        "\n",
        "# Select best target image from sample data\n",
        "print(\"üéØ Evaluating images for optimal target selection...\")\n",
        "target_candidates = []\n",
        "\n",
        "for tissue in selected_tissues:\n",
        "    for split in ['train', 'test', 'val']:\n",
        "        for img_path, mask_path in sample_data[tissue][split][:2]:  # Check first 2 from each split\n",
        "            try:\n",
        "                img = cv2.imread(str(img_path))\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img_tensor = torch.from_numpy(img).to(device)\n",
        "                    \n",
        "                    quality_metrics = evaluate_image_quality_gpu(img_tensor)\n",
        "                    \n",
        "                    target_candidates.append({\n",
        "                        'tissue': tissue,\n",
        "                        'split': split,\n",
        "                        'path': img_path,\n",
        "                        'image': img,\n",
        "                        **quality_metrics\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Failed to evaluate {img_path}: {e}\")\n",
        "\n",
        "# Select best target\n",
        "if target_candidates:\n",
        "    target_candidates.sort(key=lambda x: x['quality_score'], reverse=True)\n",
        "    best_target = target_candidates[0]\n",
        "    \n",
        "    print(f\"\\\\nüèÜ Selected target image:\")\n",
        "    print(f\"   Tissue: {best_target['tissue']}\")\n",
        "    print(f\"   Split: {best_target['split']}\")\n",
        "    print(f\"   Quality score: {best_target['quality_score']:.2f}\")\n",
        "    print(f\"   Tissue coverage: {best_target['tissue_coverage']:.2f}\")\n",
        "    print(f\"   Contrast: {best_target['contrast']:.2f}\")\n",
        "    \n",
        "    target_image = best_target['image']\n",
        "    target_info = best_target\n",
        "    \n",
        "    # Save target image\n",
        "    target_save_path = artifacts_dir / 'results' / 'target_image.png'\n",
        "    Image.fromarray(target_image).save(target_save_path)\n",
        "    \n",
        "    # Save target metadata\n",
        "    target_metadata = {k: v for k, v in target_info.items() if k != 'image'}\n",
        "    target_metadata['path'] = str(target_metadata['path'])\n",
        "    \n",
        "    with open(artifacts_dir / 'results' / 'target_metadata.json', 'w') as f:\n",
        "        json.dump(target_metadata, f, indent=2)\n",
        "    \n",
        "    logger.info(f\"Target image selected: {best_target['tissue']} with quality score {best_target['quality_score']:.2f}\")\n",
        "else:\n",
        "    raise ValueError(\"No valid target candidates found!\")\n",
        "\n",
        "# Test normalizer with target\n",
        "print(f\"\\\\nüîß Fitting normalizer to target image...\")\n",
        "start_time = time.time()\n",
        "gpu_normalizer.fit(target_image)\n",
        "fit_time = time.time() - start_time\n",
        "\n",
        "print(f\"‚úÖ Normalizer fitted successfully in {fit_time:.3f}s\")\n",
        "logger.info(f\"GPU normalizer fitted in {fit_time:.3f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Apply Normalization to Sample Dataset\n",
        "\n",
        "Process all sample images with GPU-accelerated batch normalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# BATCH NORMALIZATION PROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "logger.info(\"Starting batch normalization of sample dataset...\")\n",
        "\n",
        "# Create directories for normalized datasets\n",
        "normalized_base = artifacts_dir / 'datasets' / 'normalized'\n",
        "original_base = artifacts_dir / 'datasets' / 'original'\n",
        "\n",
        "for base_dir in [normalized_base, original_base]:\n",
        "    for tissue in selected_tissues:\n",
        "        for split in ['train', 'test', 'val']:\n",
        "            (base_dir / tissue / split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "            (base_dir / tissue / split / 'masks').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Process images in batches\n",
        "normalization_results = {}\n",
        "processing_stats = {\n",
        "    'total_processed': 0,\n",
        "    'total_failed': 0,\n",
        "    'processing_time': 0,\n",
        "    'tissues_processed': {}\n",
        "}\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for tissue in selected_tissues:\n",
        "    print(f\"\\\\nüîÑ Processing {tissue}...\")\n",
        "    tissue_results = {'train': [], 'test': [], 'val': []}\n",
        "    tissue_stats = {'processed': 0, 'failed': 0}\n",
        "    \n",
        "    for split in ['train', 'test', 'val']:\n",
        "        split_pairs = sample_data[tissue][split]\n",
        "        if not split_pairs:\n",
        "            continue\n",
        "            \n",
        "        print(f\"   {split}: {len(split_pairs)} images\")\n",
        "        \n",
        "        # Process in batches for GPU efficiency\n",
        "        batch_size = min(8, len(split_pairs))  # Adjust based on memory\n",
        "        \n",
        "        for i in range(0, len(split_pairs), batch_size):\n",
        "            batch_pairs = split_pairs[i:i+batch_size]\n",
        "            batch_images = []\n",
        "            batch_masks = []\n",
        "            batch_metadata = []\n",
        "            \n",
        "            # Load batch\n",
        "            for img_path, mask_path in batch_pairs:\n",
        "                try:\n",
        "                    # Load image\n",
        "                    img = cv2.imread(str(img_path))\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    \n",
        "                    # Load mask\n",
        "                    mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "                    \n",
        "                    batch_images.append(img)\n",
        "                    batch_masks.append(mask)\n",
        "                    batch_metadata.append({\n",
        "                        'tissue': tissue,\n",
        "                        'split': split,\n",
        "                        'original_img_path': str(img_path),\n",
        "                        'original_mask_path': str(mask_path),\n",
        "                        'filename': img_path.name\n",
        "                    })\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Failed to load {img_path}: {e}\")\n",
        "                    tissue_stats['failed'] += 1\n",
        "                    processing_stats['total_failed'] += 1\n",
        "            \n",
        "            if not batch_images:\n",
        "                continue\n",
        "            \n",
        "            try:\n",
        "                # Apply normalization to batch\n",
        "                batch_start = time.time()\n",
        "                normalized_batch = gpu_normalizer.transform_batch(batch_images)\n",
        "                batch_time = time.time() - batch_start\n",
        "                \n",
        "                # Save results\n",
        "                for j, (orig_img, norm_img, mask, metadata) in enumerate(\n",
        "                    zip(batch_images, normalized_batch, batch_masks, batch_metadata)\n",
        "                ):\n",
        "                    # Generate unique filename\n",
        "                    base_name = f\"{tissue}_{split}_{i+j:04d}\"\n",
        "                    \n",
        "                    # Save original\n",
        "                    orig_img_path = original_base / tissue / split / 'images' / f\"{base_name}.png\"\n",
        "                    orig_mask_path = original_base / tissue / split / 'masks' / f\"{base_name}.png\"\n",
        "                    \n",
        "                    Image.fromarray(orig_img).save(orig_img_path)\n",
        "                    Image.fromarray(mask).save(orig_mask_path)\n",
        "                    \n",
        "                    # Save normalized\n",
        "                    norm_img_path = normalized_base / tissue / split / 'images' / f\"{base_name}.png\"\n",
        "                    norm_mask_path = normalized_base / tissue / split / 'masks' / f\"{base_name}.png\"\n",
        "                    \n",
        "                    Image.fromarray(norm_img).save(norm_img_path)\n",
        "                    Image.fromarray(mask).save(norm_mask_path)  # Same mask for both\n",
        "                    \n",
        "                    # Store metadata\n",
        "                    result_metadata = {\n",
        "                        **metadata,\n",
        "                        'normalized_img_path': str(norm_img_path),\n",
        "                        'normalized_mask_path': str(norm_mask_path),\n",
        "                        'original_saved_img_path': str(orig_img_path),\n",
        "                        'original_saved_mask_path': str(orig_mask_path),\n",
        "                        'processing_time': batch_time / len(batch_images),\n",
        "                        'base_name': base_name\n",
        "                    }\n",
        "                    \n",
        "                    tissue_results[split].append(result_metadata)\n",
        "                    tissue_stats['processed'] += 1\n",
        "                    processing_stats['total_processed'] += 1\n",
        "                \n",
        "                print(f\"      Batch {i//batch_size + 1}: {len(batch_images)} images in {batch_time:.3f}s\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                logger.error(f\"Batch normalization failed: {e}\")\n",
        "                tissue_stats['failed'] += len(batch_images)\n",
        "                processing_stats['total_failed'] += len(batch_images)\n",
        "    \n",
        "    normalization_results[tissue] = tissue_results\n",
        "    processing_stats['tissues_processed'][tissue] = tissue_stats\n",
        "    \n",
        "    print(f\"   ‚úÖ {tissue}: {tissue_stats['processed']} processed, {tissue_stats['failed']} failed\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "processing_stats['processing_time'] = total_time\n",
        "\n",
        "# Summary\n",
        "print(f\"\\\\nüéâ Normalization Complete!\")\n",
        "print(f\"   üìä Processed: {processing_stats['total_processed']} images\")\n",
        "print(f\"   ‚ùå Failed: {processing_stats['total_failed']} images\")\n",
        "print(f\"   ‚è±Ô∏è  Total time: {total_time:.2f}s\")\n",
        "print(f\"   ‚ö° Speed: {processing_stats['total_processed']/total_time:.1f} images/sec\")\n",
        "\n",
        "# Save processing results\n",
        "with open(artifacts_dir / 'results' / 'normalization_results.json', 'w') as f:\n",
        "    json.dump(normalization_results, f, indent=2, default=str)\n",
        "\n",
        "with open(artifacts_dir / 'results' / 'processing_stats.json', 'w') as f:\n",
        "    json.dump(processing_stats, f, indent=2)\n",
        "\n",
        "logger.info(f\"Normalization completed: {processing_stats['total_processed']} images processed in {total_time:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training and Evaluation\n",
        "\n",
        "### 3.1 Create Dataset Classes and DataLoaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DATASET CLASSES AND DATALOADERS\n",
        "# =============================================================================\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    \"\"\"Dataset class for nuclei segmentation\"\"\"\n",
        "    \n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = Path(image_dir)\n",
        "        self.mask_dir = Path(mask_dir)\n",
        "        self.transform = transform\n",
        "        \n",
        "        # Get all image files\n",
        "        self.image_files = sorted(list(self.image_dir.glob('*.png')))\n",
        "        self.mask_files = sorted(list(self.mask_dir.glob('*.png')))\n",
        "        \n",
        "        # Ensure we have matching pairs\n",
        "        assert len(self.image_files) == len(self.mask_files), \\\n",
        "            f\"Mismatch: {len(self.image_files)} images, {len(self.mask_files)} masks\"\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img_path = self.image_files[idx]\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Load mask\n",
        "        mask_path = self.mask_files[idx]\n",
        "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
        "        \n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = torch.from_numpy(mask).long()\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
        "            mask = torch.from_numpy(mask).long()\n",
        "        \n",
        "        return image, mask\n",
        "\n",
        "# Define transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders for both original and normalized data\n",
        "def create_dataloaders(data_type='original', batch_size=4, num_workers=2):\n",
        "    \"\"\"Create dataloaders for specified data type (original or normalized)\"\"\"\n",
        "    \n",
        "    base_dir = artifacts_dir / 'datasets' / data_type\n",
        "    dataloaders = {}\n",
        "    \n",
        "    for split in ['train', 'val']:  # Skip test for now, use val for evaluation\n",
        "        # Combine all tissues for the split\n",
        "        all_images = []\n",
        "        all_masks = []\n",
        "        \n",
        "        for tissue in selected_tissues:\n",
        "            tissue_img_dir = base_dir / tissue / split / 'images'\n",
        "            tissue_mask_dir = base_dir / tissue / split / 'masks'\n",
        "            \n",
        "            if tissue_img_dir.exists() and tissue_mask_dir.exists():\n",
        "                tissue_images = list(tissue_img_dir.glob('*.png'))\n",
        "                tissue_masks = list(tissue_mask_dir.glob('*.png'))\n",
        "                \n",
        "                all_images.extend(tissue_images)\n",
        "                all_masks.extend(tissue_masks)\n",
        "        \n",
        "        if not all_images:\n",
        "            continue\n",
        "        \n",
        "        print(f\"   {data_type} {split}: {len(all_images)} images\")\n",
        "        \n",
        "        # Create temporary combined directory structure\n",
        "        temp_dir = artifacts_dir / 'temp' / data_type / split\n",
        "        temp_img_dir = temp_dir / 'images'\n",
        "        temp_mask_dir = temp_dir / 'masks'\n",
        "        temp_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "        temp_mask_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # Copy files to temporary structure (just create symlinks for efficiency)\n",
        "        for i, (img_file, mask_file) in enumerate(zip(all_images, all_masks)):\n",
        "            temp_img_file = temp_img_dir / f\"{i:04d}.png\"\n",
        "            temp_mask_file = temp_mask_dir / f\"{i:04d}.png\"\n",
        "            \n",
        "            # Create symlinks or copy files\n",
        "            if not temp_img_file.exists():\n",
        "                try:\n",
        "                    temp_img_file.symlink_to(img_file.absolute())\n",
        "                    temp_mask_file.symlink_to(mask_file.absolute())\n",
        "                except:\n",
        "                    # Fallback to copying if symlinks fail\n",
        "                    import shutil\n",
        "                    shutil.copy2(img_file, temp_img_file)\n",
        "                    shutil.copy2(mask_file, temp_mask_file)\n",
        "        \n",
        "        # Create dataset\n",
        "        transform = train_transform if split == 'train' else val_transform\n",
        "        dataset = SegmentationDataset(temp_img_dir, temp_mask_dir, transform=transform)\n",
        "        \n",
        "        # Create dataloader\n",
        "        dataloader = DataLoader(\n",
        "            dataset, \n",
        "            batch_size=batch_size, \n",
        "            shuffle=(split == 'train'),\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=True\n",
        "        )\n",
        "        \n",
        "        dataloaders[split] = dataloader\n",
        "    \n",
        "    return dataloaders\n",
        "\n",
        "# Create dataloaders\n",
        "print(\"üìä Creating dataloaders...\")\n",
        "original_dataloaders = create_dataloaders('original', batch_size=4)\n",
        "normalized_dataloaders = create_dataloaders('normalized', batch_size=4)\n",
        "\n",
        "print(f\"‚úÖ Dataloaders created:\")\n",
        "for data_type, loaders in [('original', original_dataloaders), ('normalized', normalized_dataloaders)]:\n",
        "    print(f\"   {data_type}:\")\n",
        "    for split, loader in loaders.items():\n",
        "        print(f\"     {split}: {len(loader)} batches, {len(loader.dataset)} images\")\n",
        "\n",
        "logger.info(\"Dataloaders created successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Train U-Net Models\n",
        "\n",
        "Train separate U-Net models on original and normalized data for comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MODEL TRAINING\n",
        "# =============================================================================\n",
        "\n",
        "from src.models.unet_rq3 import create_unet_rq3\n",
        "from src.utils.metrics import calculate_batch_metrics, evaluate_model_on_dataset\n",
        "\n",
        "def train_model(dataloaders, model_name, epochs=5, learning_rate=1e-4):\n",
        "    \"\"\"Train a U-Net model and return training history\"\"\"\n",
        "    \n",
        "    print(f\"\\\\nüöÄ Training {model_name} model...\")\n",
        "    \n",
        "    # Create RQ3-specific model (separate from RQ2)\n",
        "    model = create_unet_rq3(n_channels=3, n_classes=6, device=device)\n",
        "    \n",
        "    # Define loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=255)  # Ignore unknown pixels\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
        "    \n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_metrics': [],\n",
        "        'val_metrics': []\n",
        "    }\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\\\nüìÖ Epoch {epoch+1}/{epochs}\")\n",
        "        \n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_metrics_list = []\n",
        "        \n",
        "        for batch_idx, (images, masks) in enumerate(dataloaders['train']):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            \n",
        "            # Calculate metrics for this batch\n",
        "            with torch.no_grad():\n",
        "                predictions = torch.argmax(outputs, dim=1)\n",
        "                batch_metrics = calculate_batch_metrics(predictions, masks, num_classes=6)\n",
        "                train_metrics_list.append(batch_metrics)\n",
        "            \n",
        "            if batch_idx % 5 == 0:  # Print every 5 batches\n",
        "                print(f\"   Batch {batch_idx+1}/{len(dataloaders['train'])}: Loss = {loss.item():.4f}\")\n",
        "        \n",
        "        # Average training metrics\n",
        "        avg_train_loss = train_loss / len(dataloaders['train'])\n",
        "        avg_train_metrics = {}\n",
        "        for key in train_metrics_list[0].keys():\n",
        "            avg_train_metrics[key] = np.mean([m[key] for m in train_metrics_list if not np.isnan(m[key])])\n",
        "        \n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_metrics_list = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for images, masks in dataloaders['val']:\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks)\n",
        "                val_loss += loss.item()\n",
        "                \n",
        "                # Calculate metrics\n",
        "                predictions = torch.argmax(outputs, dim=1)\n",
        "                batch_metrics = calculate_batch_metrics(predictions, masks, num_classes=6)\n",
        "                val_metrics_list.append(batch_metrics)\n",
        "        \n",
        "        avg_val_loss = val_loss / len(dataloaders['val'])\n",
        "        avg_val_metrics = {}\n",
        "        for key in val_metrics_list[0].keys():\n",
        "            avg_val_metrics[key] = np.mean([m[key] for m in val_metrics_list if not np.isnan(m[key])])\n",
        "        \n",
        "        # Update history\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['train_metrics'].append(avg_train_metrics)\n",
        "        history['val_metrics'].append(avg_val_metrics)\n",
        "        \n",
        "        # Print epoch summary\n",
        "        print(f\"   üìä Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"   üìà Train Dice: {avg_train_metrics.get('avg_dice', 0):.4f}, Val Dice: {avg_val_metrics.get('avg_dice', 0):.4f}\")\n",
        "        \n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), artifacts_dir / 'checkpoints' / f'{model_name}_best.pth')\n",
        "            print(f\"   üíæ Best model saved (Val Loss: {best_val_loss:.4f})\")\n",
        "        \n",
        "        scheduler.step()\n",
        "    \n",
        "    # Save final model\n",
        "    torch.save(model.state_dict(), artifacts_dir / 'checkpoints' / f'{model_name}_final.pth')\n",
        "    \n",
        "    # Save training history\n",
        "    with open(artifacts_dir / 'results' / f'{model_name}_history.json', 'w') as f:\n",
        "        json.dump(history, f, indent=2, default=str)\n",
        "    \n",
        "    print(f\"‚úÖ {model_name} training completed!\")\n",
        "    return model, history\n",
        "\n",
        "# Training configuration\n",
        "EPOCHS = 3 if TESTING_MODE else 10  # Fewer epochs for testing\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Train both models\n",
        "models = {}\n",
        "histories = {}\n",
        "\n",
        "# Train model on original data\n",
        "if 'train' in original_dataloaders:\n",
        "    model_original, history_original = train_model(\n",
        "        original_dataloaders, \n",
        "        'unet_original', \n",
        "        epochs=EPOCHS, \n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "    models['original'] = model_original\n",
        "    histories['original'] = history_original\n",
        "\n",
        "# Train model on normalized data\n",
        "if 'train' in normalized_dataloaders:\n",
        "    model_normalized, history_normalized = train_model(\n",
        "        normalized_dataloaders, \n",
        "        'unet_normalized', \n",
        "        epochs=EPOCHS, \n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "    models['normalized'] = model_normalized\n",
        "    histories['normalized'] = history_normalized\n",
        "\n",
        "print(f\"\\\\nüéâ All models trained successfully!\")\n",
        "logger.info(f\"Model training completed: {len(models)} models trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Paired Evaluation and Statistical Analysis\n",
        "\n",
        "Evaluate both models on the same test images and perform statistical comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PAIRED EVALUATION AND STATISTICAL ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate_models_paired(models, dataloaders):\n",
        "    \"\"\"Evaluate models on paired data for statistical comparison\"\"\"\n",
        "    \n",
        "    print(\"üîç Performing paired evaluation...\")\n",
        "    \n",
        "    # Results storage\n",
        "    paired_results = []\n",
        "    \n",
        "    # Get validation dataloaders\n",
        "    original_val = dataloaders['original']['val'] if 'val' in dataloaders['original'] else None\n",
        "    normalized_val = dataloaders['normalized']['val'] if 'val' in dataloaders['normalized'] else None\n",
        "    \n",
        "    if not (original_val and normalized_val):\n",
        "        print(\"‚ö†Ô∏è  Validation dataloaders not available for paired evaluation\")\n",
        "        return []\n",
        "    \n",
        "    # Ensure both models are in evaluation mode\n",
        "    models['original'].eval()\n",
        "    models['normalized'].eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Get iterators\n",
        "        orig_iter = iter(original_val)\n",
        "        norm_iter = iter(normalized_val)\n",
        "        \n",
        "        batch_count = min(len(original_val), len(normalized_val))\n",
        "        \n",
        "        for batch_idx in range(batch_count):\n",
        "            try:\n",
        "                # Get paired batches\n",
        "                orig_images, orig_masks = next(orig_iter)\n",
        "                norm_images, norm_masks = next(norm_iter)\n",
        "                \n",
        "                # Move to device\n",
        "                orig_images, orig_masks = orig_images.to(device), orig_masks.to(device)\n",
        "                norm_images, norm_masks = norm_images.to(device), norm_masks.to(device)\n",
        "                \n",
        "                # Get predictions\n",
        "                orig_outputs = models['original'](orig_images)\n",
        "                norm_outputs = models['normalized'](norm_images)\n",
        "                \n",
        "                orig_preds = torch.argmax(orig_outputs, dim=1)\n",
        "                norm_preds = torch.argmax(norm_outputs, dim=1)\n",
        "                \n",
        "                # Calculate metrics for each image in batch\n",
        "                batch_size = orig_images.shape[0]\n",
        "                \n",
        "                for i in range(batch_size):\n",
        "                    # Get individual predictions and masks\n",
        "                    orig_pred = orig_preds[i].cpu().numpy()\n",
        "                    norm_pred = norm_preds[i].cpu().numpy()\n",
        "                    orig_mask = orig_masks[i].cpu().numpy()\n",
        "                    norm_mask = norm_masks[i].cpu().numpy()\n",
        "                    \n",
        "                    # Calculate metrics for original model\n",
        "                    orig_metrics = calculate_segmentation_metrics(orig_pred, orig_mask, num_classes=6)\n",
        "                    \n",
        "                    # Calculate metrics for normalized model  \n",
        "                    norm_metrics = calculate_segmentation_metrics(norm_pred, norm_mask, num_classes=6)\n",
        "                    \n",
        "                    # Store paired results\n",
        "                    paired_result = {\n",
        "                        'batch_idx': batch_idx,\n",
        "                        'image_idx': i,\n",
        "                        'original_dice': orig_metrics['avg_dice'],\n",
        "                        'normalized_dice': norm_metrics['avg_dice'],\n",
        "                        'original_iou': orig_metrics['avg_iou'],\n",
        "                        'normalized_iou': norm_metrics['avg_iou'],\n",
        "                        'original_pixel_acc': orig_metrics['pixel_accuracy'],\n",
        "                        'normalized_pixel_acc': norm_metrics['pixel_accuracy'],\n",
        "                        'original_precision': orig_metrics['avg_precision'],\n",
        "                        'normalized_precision': norm_metrics['avg_precision'],\n",
        "                        'original_recall': orig_metrics['avg_recall'],\n",
        "                        'normalized_recall': norm_metrics['avg_recall'],\n",
        "                        'original_f1': orig_metrics['avg_f1'],\n",
        "                        'normalized_f1': norm_metrics['avg_f1']\n",
        "                    }\n",
        "                    \n",
        "                    paired_results.append(paired_result)\n",
        "                \n",
        "                if batch_idx % 5 == 0:\n",
        "                    print(f\"   Processed batch {batch_idx+1}/{batch_count}\")\n",
        "                    \n",
        "            except StopIteration:\n",
        "                break\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error in batch {batch_idx}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    print(f\"‚úÖ Paired evaluation completed: {len(paired_results)} image pairs\")\n",
        "    return paired_results\n",
        "\n",
        "# Perform paired evaluation\n",
        "if len(models) == 2:\n",
        "    paired_results = evaluate_models_paired(models, {'original': original_dataloaders, 'normalized': normalized_dataloaders})\n",
        "    \n",
        "    if paired_results:\n",
        "        # Convert to DataFrame for analysis\n",
        "        results_df = pd.DataFrame(paired_results)\n",
        "        \n",
        "        # Save paired results\n",
        "        results_df.to_csv(artifacts_dir / 'results' / 'paired_evaluation_results.csv', index=False)\n",
        "        \n",
        "        # Statistical Analysis\n",
        "        print(\"\\\\nüìä Statistical Analysis:\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        metrics_to_test = ['dice', 'iou', 'pixel_acc', 'precision', 'recall', 'f1']\n",
        "        statistical_results = {}\n",
        "        \n",
        "        for metric in metrics_to_test:\n",
        "            original_col = f'original_{metric}'\n",
        "            normalized_col = f'normalized_{metric}'\n",
        "            \n",
        "            if original_col in results_df.columns and normalized_col in results_df.columns:\n",
        "                original_vals = results_df[original_col].dropna()\n",
        "                normalized_vals = results_df[normalized_col].dropna()\n",
        "                \n",
        "                if len(original_vals) > 0 and len(normalized_vals) > 0:\n",
        "                    # Ensure same length for paired tests\n",
        "                    min_len = min(len(original_vals), len(normalized_vals))\n",
        "                    original_vals = original_vals[:min_len]\n",
        "                    normalized_vals = normalized_vals[:min_len]\n",
        "                    \n",
        "                    # Calculate basic statistics\n",
        "                    orig_mean = np.mean(original_vals)\n",
        "                    norm_mean = np.mean(normalized_vals)\n",
        "                    improvement = ((norm_mean - orig_mean) / orig_mean) * 100\n",
        "                    \n",
        "                    # Wilcoxon signed-rank test (non-parametric paired test)\n",
        "                    try:\n",
        "                        wilcoxon_stat, wilcoxon_p = wilcoxon(normalized_vals, original_vals, alternative='two-sided')\n",
        "                    except:\n",
        "                        wilcoxon_stat, wilcoxon_p = np.nan, np.nan\n",
        "                    \n",
        "                    # Paired t-test (parametric paired test)\n",
        "                    try:\n",
        "                        ttest_stat, ttest_p = ttest_rel(normalized_vals, original_vals)\n",
        "                    except:\n",
        "                        ttest_stat, ttest_p = np.nan, np.nan\n",
        "                    \n",
        "                    # Store results\n",
        "                    statistical_results[metric] = {\n",
        "                        'original_mean': orig_mean,\n",
        "                        'normalized_mean': norm_mean,\n",
        "                        'improvement_percent': improvement,\n",
        "                        'wilcoxon_statistic': wilcoxon_stat,\n",
        "                        'wilcoxon_p_value': wilcoxon_p,\n",
        "                        'ttest_statistic': ttest_stat,\n",
        "                        'ttest_p_value': ttest_p,\n",
        "                        'sample_size': min_len,\n",
        "                        'significant_wilcoxon': wilcoxon_p < 0.05 if not np.isnan(wilcoxon_p) else False,\n",
        "                        'significant_ttest': ttest_p < 0.05 if not np.isnan(ttest_p) else False\n",
        "                    }\n",
        "                    \n",
        "                    # Print results\n",
        "                    print(f\"\\\\n{metric.upper()}:\")\n",
        "                    print(f\"  Original:    {orig_mean:.4f}\")\n",
        "                    print(f\"  Normalized:  {norm_mean:.4f}\")\n",
        "                    print(f\"  Improvement: {improvement:+.2f}%\")\n",
        "                    print(f\"  Wilcoxon p:  {wilcoxon_p:.6f} {'***' if wilcoxon_p < 0.001 else '**' if wilcoxon_p < 0.01 else '*' if wilcoxon_p < 0.05 else ''}\")\n",
        "                    print(f\"  T-test p:    {ttest_p:.6f} {'***' if ttest_p < 0.001 else '**' if ttest_p < 0.01 else '*' if ttest_p < 0.05 else ''}\")\n",
        "        \n",
        "        # Save statistical results\n",
        "        stats_df = pd.DataFrame(statistical_results).T\n",
        "        stats_df.to_csv(artifacts_dir / 'results' / 'statistical_analysis.csv')\n",
        "        \n",
        "        with open(artifacts_dir / 'results' / 'statistical_results.json', 'w') as f:\n",
        "            json.dump(statistical_results, f, indent=2, default=str)\n",
        "        \n",
        "        # Summary of hypothesis testing\n",
        "        print(\"\\\\nüß™ Hypothesis Testing Summary:\")\n",
        "        print(\"=\" * 40)\n",
        "        \n",
        "        significant_metrics = []\n",
        "        for metric, results in statistical_results.items():\n",
        "            if results['significant_wilcoxon'] or results['significant_ttest']:\n",
        "                significant_metrics.append(metric)\n",
        "                improvement = results['improvement_percent']\n",
        "                direction = \"improvement\" if improvement > 0 else \"degradation\"\n",
        "                print(f\"‚úÖ {metric.upper()}: Significant {direction} ({improvement:+.2f}%)\")\n",
        "            else:\n",
        "                print(f\"‚ùå {metric.upper()}: No significant difference\")\n",
        "        \n",
        "        # Final conclusion\n",
        "        print(f\"\\\\nüéØ RESEARCH QUESTION 3 RESULTS:\")\n",
        "        print(\"=\" * 35)\n",
        "        \n",
        "        if significant_metrics:\n",
        "            print(f\"üéâ REJECT NULL HYPOTHESIS (H‚ÇÄ)\")\n",
        "            print(f\"   Stain normalization shows significant improvement in:\")\n",
        "            for metric in significant_metrics:\n",
        "                improvement = statistical_results[metric]['improvement_percent']\n",
        "                print(f\"   - {metric.upper()}: {improvement:+.2f}%\")\n",
        "        else:\n",
        "            print(f\"üìä FAIL TO REJECT NULL HYPOTHESIS (H‚ÇÄ)\")\n",
        "            print(f\"   No significant improvement found with stain normalization\")\n",
        "        \n",
        "        logger.info(f\"Statistical analysis completed: {len(statistical_results)} metrics analyzed\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Both models not available for paired evaluation\")\n",
        "    \n",
        "print(\"\\\\n‚úÖ RQ3 Analysis Pipeline Completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summary and Artifacts\n",
        "\n",
        "### Complete RQ3 Pipeline Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FINAL SUMMARY AND ARTIFACT DOCUMENTATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üìã RQ3 Complete Pipeline Summary\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Pipeline execution summary\n",
        "execution_summary = {\n",
        "    'pipeline_completed': True,\n",
        "    'testing_mode': TESTING_MODE,\n",
        "    'total_tissues': len(selected_tissues),\n",
        "    'selected_tissues': selected_tissues,\n",
        "    'total_sample_images': total_sample_images if 'total_sample_images' in locals() else 0,\n",
        "    'models_trained': len(models) if 'models' in locals() else 0,\n",
        "    'statistical_analysis_completed': 'statistical_results' in locals(),\n",
        "    'gpu_acceleration_used': device.type == 'cuda',\n",
        "    'execution_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "\n",
        "print(f\"üéØ Pipeline Status: {'‚úÖ COMPLETED' if execution_summary['pipeline_completed'] else '‚ùå INCOMPLETE'}\")\n",
        "print(f\"üß™ Mode: {'TESTING' if execution_summary['testing_mode'] else 'PRODUCTION'}\")\n",
        "print(f\"üî¨ Tissues: {execution_summary['total_tissues']} ({', '.join(execution_summary['selected_tissues'])})\")\n",
        "print(f\"üìä Images: {execution_summary['total_sample_images']:,}\")\n",
        "print(f\"ü§ñ Models: {execution_summary['models_trained']} trained\")\n",
        "print(f\"üìà Statistics: {'‚úÖ Completed' if execution_summary['statistical_analysis_completed'] else '‚ùå Pending'}\")\n",
        "print(f\"‚ö° GPU: {'‚úÖ Used' if execution_summary['gpu_acceleration_used'] else '‚ùå CPU only'}\")\n",
        "\n",
        "# Document all artifacts\n",
        "print(f\"\\nüìÅ Generated Artifacts:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "artifact_categories = {\n",
        "    'datasets': 'Processed image datasets (original & normalized)',\n",
        "    'checkpoints': 'Trained model weights',\n",
        "    'results': 'Analysis results and statistics', \n",
        "    'plots': 'Visualizations and plots',\n",
        "    'logs': 'Execution logs'\n",
        "}\n",
        "\n",
        "for category, description in artifact_categories.items():\n",
        "    category_path = artifacts_dir / category\n",
        "    if category_path.exists():\n",
        "        file_count = len(list(category_path.rglob('*')))\n",
        "        print(f\"üìÇ {category:12}: {file_count:3} files - {description}\")\n",
        "\n",
        "# Key result files\n",
        "key_files = [\n",
        "    'tissue_selection.json',\n",
        "    'sample_config.json', \n",
        "    'target_metadata.json',\n",
        "    'normalization_results.json',\n",
        "    'processing_stats.json',\n",
        "    'paired_evaluation_results.csv',\n",
        "    'statistical_analysis.csv',\n",
        "    'statistical_results.json'\n",
        "]\n",
        "\n",
        "print(f\"\\nüìã Key Result Files:\")\n",
        "for filename in key_files:\n",
        "    filepath = artifacts_dir / 'results' / filename\n",
        "    status = '‚úÖ' if filepath.exists() else '‚ùå'\n",
        "    print(f\"   {status} {filename}\")\n",
        "\n",
        "# Research question conclusion\n",
        "print(f\"\\nüéØ Research Question 3 Conclusion:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if 'statistical_results' in locals() and statistical_results:\n",
        "    # Count significant improvements\n",
        "    significant_count = sum(1 for metric, results in statistical_results.items() \n",
        "                          if results.get('significant_wilcoxon', False) or results.get('significant_ttest', False))\n",
        "    \n",
        "    total_metrics = len(statistical_results)\n",
        "    \n",
        "    if significant_count > 0:\n",
        "        print(\"üéâ CONCLUSION: REJECT NULL HYPOTHESIS (H‚ÇÄ)\")\n",
        "        print(f\"   üìä {significant_count}/{total_metrics} metrics show significant improvement\")\n",
        "        print(\"   üìà Stain normalization DOES improve U-Net segmentation performance\")\n",
        "        \n",
        "        # Show top improvements\n",
        "        improvements = [(metric, results['improvement_percent']) \n",
        "                       for metric, results in statistical_results.items()\n",
        "                       if results.get('significant_wilcoxon', False) or results.get('significant_ttest', False)]\n",
        "        \n",
        "        if improvements:\n",
        "            improvements.sort(key=lambda x: abs(x[1]), reverse=True)\n",
        "            print(\"   üèÜ Top improvements:\")\n",
        "            for metric, improvement in improvements[:3]:\n",
        "                print(f\"      - {metric.upper()}: {improvement:+.2f}%\")\n",
        "    else:\n",
        "        print(\"üìä CONCLUSION: FAIL TO REJECT NULL HYPOTHESIS (H‚ÇÄ)\")\n",
        "        print(\"   ‚ùå No significant improvement found with stain normalization\")\n",
        "        print(\"   üìâ Current evidence does not support H‚ÇÅ\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Statistical analysis not completed - cannot draw conclusion\")\n",
        "\n",
        "# Save execution summary\n",
        "with open(artifacts_dir / 'results' / 'execution_summary.json', 'w') as f:\n",
        "    json.dump(execution_summary, f, indent=2, default=str)\n",
        "\n",
        "# Performance summary\n",
        "if 'processing_stats' in locals():\n",
        "    print(f\"\\n‚ö° Performance Summary:\")\n",
        "    print(\"=\" * 25)\n",
        "    total_time = processing_stats.get('processing_time', 0)\n",
        "    total_processed = processing_stats.get('total_processed', 0)\n",
        "    \n",
        "    print(f\"üìä Images processed: {total_processed:,}\")\n",
        "    print(f\"‚è±Ô∏è  Processing time: {total_time:.2f}s\")\n",
        "    print(f\"üöÄ Processing speed: {total_processed/total_time:.1f} images/sec\" if total_time > 0 else \"üöÄ Processing speed: N/A\")\n",
        "    \n",
        "    if device.type == 'cuda':\n",
        "        estimated_full_time = (5072 * total_time / total_processed) / 60 if total_processed > 0 else 0\n",
        "        print(f\"üìà Full dataset estimate: {estimated_full_time:.1f} minutes\")\n",
        "\n",
        "print(f\"\\nüéâ RQ3 GPU-Accelerated Pipeline Complete!\")\n",
        "print(f\"üìÅ All artifacts saved to: {artifacts_dir}\")\n",
        "print(f\"üî¨ Ready for publication and further analysis\")\n",
        "\n",
        "logger.info(\"RQ3 complete pipeline execution finished successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
