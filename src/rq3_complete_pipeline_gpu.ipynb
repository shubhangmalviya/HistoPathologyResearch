{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 3: Complete GPU-Accelerated Pipeline\n",
    "## Stain Normalization Impact on U-Net Nuclei Segmentation\n",
    "\n",
    "**Research Question**: Does stain normalization improve U-Net-based nuclei instance segmentation on the PanNuke dataset compared to unnormalized data?\n",
    "\n",
    "### Hypotheses:\n",
    "- **H₀ (Null)**: No significant improvement due to normalization  \n",
    "- **H₁ (Alternative)**: Significant improvement due to normalization\n",
    "\n",
    "### Methodology:\n",
    "1. **Dataset**: Top 5 tissues from PanNuke dataset\n",
    "2. **Normalization**: Vahadane method with GPU acceleration\n",
    "3. **Models**: U-Net trained on normalized vs unnormalized data\n",
    "4. **Evaluation**: Paired statistical analysis per image\n",
    "5. **Statistics**: Wilcoxon signed-rank test, paired t-test\n",
    "\n",
    "### Expected Outcomes:\n",
    "- Comprehensive EDA before/after normalization\n",
    "- Model performance comparison\n",
    "- Statistical significance testing\n",
    "- Complete artifacts for reproducibility\n",
    "\n",
    "---\n",
    "**⚡ GPU-Accelerated Pipeline | Production Ready | Cloud Deployment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anyio (from -r ../requirements.txt (line 1))\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting appnope (from -r ../requirements.txt (line 2))\n",
      "  Using cached appnope-0.1.4-py2.py3-none-any.whl.metadata (908 bytes)\n",
      "Collecting argon2-cffi (from -r ../requirements.txt (line 3))\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting argon2-cffi-bindings (from -r ../requirements.txt (line 4))\n",
      "  Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting arrow (from -r ../requirements.txt (line 5))\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting asttokens (from -r ../requirements.txt (line 6))\n",
      "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting async-lru (from -r ../requirements.txt (line 7))\n",
      "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting attrs (from -r ../requirements.txt (line 8))\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting babel (from -r ../requirements.txt (line 9))\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting beautifulsoup4 (from -r ../requirements.txt (line 10))\n",
      "  Downloading beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach (from -r ../requirements.txt (line 11))\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting certifi (from -r ../requirements.txt (line 12))\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cffi (from -r ../requirements.txt (line 13))\n",
      "  Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting charset-normalizer (from -r ../requirements.txt (line 14))\n",
      "  Using cached charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "Collecting comm (from -r ../requirements.txt (line 15))\n",
      "  Using cached comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting contourpy (from -r ../requirements.txt (line 16))\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler (from -r ../requirements.txt (line 17))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting debugpy (from -r ../requirements.txt (line 18))\n",
      "  Using cached debugpy-1.8.16-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting decorator (from -r ../requirements.txt (line 19))\n",
      "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting defusedxml (from -r ../requirements.txt (line 20))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting executing (from -r ../requirements.txt (line 21))\n",
      "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting fastjsonschema (from -r ../requirements.txt (line 22))\n",
      "  Using cached fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting filelock (from -r ../requirements.txt (line 23))\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fonttools (from -r ../requirements.txt (line 24))\n",
      "  Downloading fonttools-4.59.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (109 kB)\n",
      "Collecting fqdn (from -r ../requirements.txt (line 25))\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting fsspec (from -r ../requirements.txt (line 26))\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11 (from -r ../requirements.txt (line 27))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting httpcore (from -r ../requirements.txt (line 28))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting httpx (from -r ../requirements.txt (line 29))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting idna (from -r ../requirements.txt (line 30))\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting imageio (from -r ../requirements.txt (line 31))\n",
      "  Using cached imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting ipykernel (from -r ../requirements.txt (line 32))\n",
      "  Using cached ipykernel-6.30.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting ipython (from -r ../requirements.txt (line 33))\n",
      "  Downloading ipython-9.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting ipython_pygments_lexers (from -r ../requirements.txt (line 34))\n",
      "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting ipywidgets (from -r ../requirements.txt (line 35))\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting isoduration (from -r ../requirements.txt (line 36))\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jedi (from -r ../requirements.txt (line 37))\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting Jinja2 (from -r ../requirements.txt (line 38))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting joblib (from -r ../requirements.txt (line 39))\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting json5 (from -r ../requirements.txt (line 40))\n",
      "  Using cached json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonpointer (from -r ../requirements.txt (line 41))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema (from -r ../requirements.txt (line 42))\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting jsonschema-specifications (from -r ../requirements.txt (line 43))\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jupyter (from -r ../requirements.txt (line 44))\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting jupyter-console (from -r ../requirements.txt (line 45))\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-events (from -r ../requirements.txt (line 46))\n",
      "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-lsp (from -r ../requirements.txt (line 47))\n",
      "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter_client (from -r ../requirements.txt (line 48))\n",
      "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jupyter_core (from -r ../requirements.txt (line 49))\n",
      "  Using cached jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyter_server (from -r ../requirements.txt (line 50))\n",
      "  Downloading jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyter_server_terminals (from -r ../requirements.txt (line 51))\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting jupyterlab (from -r ../requirements.txt (line 52))\n",
      "  Using cached jupyterlab-4.4.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting jupyterlab_pygments (from -r ../requirements.txt (line 53))\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting jupyterlab_server (from -r ../requirements.txt (line 54))\n",
      "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyterlab_widgets (from -r ../requirements.txt (line 55))\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting kiwisolver (from -r ../requirements.txt (line 56))\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lark (from -r ../requirements.txt (line 57))\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting lazy_loader (from -r ../requirements.txt (line 58))\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting MarkupSafe (from -r ../requirements.txt (line 59))\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting matplotlib (from -r ../requirements.txt (line 60))\n",
      "  Downloading matplotlib-3.10.6-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting matplotlib-inline (from -r ../requirements.txt (line 61))\n",
      "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting mistune (from -r ../requirements.txt (line 62))\n",
      "  Downloading mistune-3.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting mpmath (from -r ../requirements.txt (line 63))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting nbclient (from -r ../requirements.txt (line 64))\n",
      "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting nbconvert (from -r ../requirements.txt (line 65))\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting nbformat (from -r ../requirements.txt (line 66))\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nest-asyncio (from -r ../requirements.txt (line 67))\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting networkx (from -r ../requirements.txt (line 68))\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting notebook (from -r ../requirements.txt (line 69))\n",
      "  Using cached notebook-7.4.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting notebook_shim (from -r ../requirements.txt (line 70))\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numpy (from -r ../requirements.txt (line 71))\n",
      "  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting opencv-python (from -r ../requirements.txt (line 72))\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting overrides (from -r ../requirements.txt (line 73))\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting packaging (from -r ../requirements.txt (line 74))\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pandas (from -r ../requirements.txt (line 75))\n",
      "  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting pandas-stubs (from -r ../requirements.txt (line 76))\n",
      "  Using cached pandas_stubs-2.3.2.250827-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandocfilters (from -r ../requirements.txt (line 77))\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parso (from -r ../requirements.txt (line 78))\n",
      "  Downloading parso-0.8.5-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pexpect (from -r ../requirements.txt (line 79))\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pillow (from -r ../requirements.txt (line 80))\n",
      "  Using cached pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting platformdirs (from -r ../requirements.txt (line 81))\n",
      "  Downloading platformdirs-4.4.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting prometheus_client (from -r ../requirements.txt (line 82))\n",
      "  Using cached prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting prompt_toolkit (from -r ../requirements.txt (line 83))\n",
      "  Downloading prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting psutil (from -r ../requirements.txt (line 84))\n",
      "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting ptyprocess (from -r ../requirements.txt (line 85))\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pure_eval (from -r ../requirements.txt (line 86))\n",
      "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pycparser (from -r ../requirements.txt (line 87))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting Pygments (from -r ../requirements.txt (line 88))\n",
      "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyparsing (from -r ../requirements.txt (line 89))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil (from -r ../requirements.txt (line 90))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting python-json-logger (from -r ../requirements.txt (line 91))\n",
      "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pytz (from -r ../requirements.txt (line 92))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML (from -r ../requirements.txt (line 93))\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pyzmq (from -r ../requirements.txt (line 94))\n",
      "  Downloading pyzmq-27.0.2-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting referencing (from -r ../requirements.txt (line 95))\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting requests (from -r ../requirements.txt (line 96))\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting rfc3339-validator (from -r ../requirements.txt (line 97))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator (from -r ../requirements.txt (line 98))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting rfc3987-syntax (from -r ../requirements.txt (line 99))\n",
      "  Using cached rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting rpds-py (from -r ../requirements.txt (line 100))\n",
      "  Downloading rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting scikit-image (from -r ../requirements.txt (line 101))\n",
      "  Using cached scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting scikit-learn (from -r ../requirements.txt (line 102))\n",
      "  Using cached scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from -r ../requirements.txt (line 103))\n",
      "  Using cached scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting scipy-stubs (from -r ../requirements.txt (line 104))\n",
      "  Using cached scipy_stubs-1.16.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting seaborn (from -r ../requirements.txt (line 105))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting Send2Trash (from -r ../requirements.txt (line 106))\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting six (from -r ../requirements.txt (line 107))\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting sniffio (from -r ../requirements.txt (line 108))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting soupsieve (from -r ../requirements.txt (line 109))\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting stack-data (from -r ../requirements.txt (line 110))\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sympy (from -r ../requirements.txt (line 111))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting terminado (from -r ../requirements.txt (line 112))\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting threadpoolctl (from -r ../requirements.txt (line 113))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tifffile (from -r ../requirements.txt (line 114))\n",
      "  Downloading tifffile-2025.8.28-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting tinycss2 (from -r ../requirements.txt (line 115))\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting torch (from -r ../requirements.txt (line 116))\n",
      "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision (from -r ../requirements.txt (line 117))\n",
      "  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting tornado (from -r ../requirements.txt (line 118))\n",
      "  Using cached tornado-6.5.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting tqdm (from -r ../requirements.txt (line 119))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting traitlets (from -r ../requirements.txt (line 120))\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting types-python-dateutil (from -r ../requirements.txt (line 121))\n",
      "  Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting typing_extensions (from -r ../requirements.txt (line 122))\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting tzdata (from -r ../requirements.txt (line 123))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting uri-template (from -r ../requirements.txt (line 124))\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting urllib3 (from -r ../requirements.txt (line 125))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting wcwidth (from -r ../requirements.txt (line 126))\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting webcolors (from -r ../requirements.txt (line 127))\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting webencodings (from -r ../requirements.txt (line 128))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting websocket-client (from -r ../requirements.txt (line 129))\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting widgetsnbextension (from -r ../requirements.txt (line 130))\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting statsmodels (from -r ../requirements.txt (line 131))\n",
      "  Downloading statsmodels-0.14.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting pyarrow (from -r ../requirements.txt (line 132))\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->-r ../requirements.txt (line 52)) (77.0.1)\n",
      "Collecting numpy (from -r ../requirements.txt (line 71))\n",
      "  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in /usr/local/lib/python3.11/dist-packages (from pandas-stubs->-r ../requirements.txt (line 76)) (2025.2.0.20250809)\n",
      "Requirement already satisfied: optype<0.14,>=0.13.4 in /usr/local/lib/python3.11/dist-packages (from optype[numpy]<0.14,>=0.13.4->scipy-stubs->-r ../requirements.txt (line 104)) (0.13.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch->-r ../requirements.txt (line 116))\n",
      "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->-r ../requirements.txt (line 131)) (1.0.1)\n",
      "Requirement already satisfied: numpy-typing-compat<20250819,>=20250818.1.25 in /usr/local/lib/python3.11/dist-packages (from optype[numpy]<0.14,>=0.13.4->scipy-stubs->-r ../requirements.txt (line 104)) (20250818.2.2)\n",
      "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\n",
      "Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (87 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n",
      "Using cached comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
      "Using cached contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached debugpy-1.8.16-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
      "Using cached fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fonttools-4.59.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Using cached ipykernel-6.30.1-py3-none-any.whl (117 kB)\n",
      "Downloading ipython-9.5.0-py3-none-any.whl (612 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.4/612.4 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "Using cached jupyter_core-5.8.1-py3-none-any.whl (28 kB)\n",
      "Downloading jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached jupyterlab-4.4.6-py3-none-any.whl (12.3 MB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "Using cached lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading matplotlib-3.10.6-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m144.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Downloading mistune-3.1.4-py3-none-any.whl (53 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached notebook-7.4.5-py3-none-any.whl (14.3 MB)\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m243.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pandas_stubs-2.3.2.250827-py3-none-any.whl (157 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading parso-0.8.5-py2.py3-none-any.whl (106 kB)\n",
      "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "Using cached pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Downloading platformdirs-4.4.0-py3-none-any.whl (18 kB)\n",
      "Using cached prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Downloading prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
      "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyzmq-27.0.2-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (856 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.0/857.0 kB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Downloading rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
      "Using cached scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "Using cached scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "Using cached scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.4 MB)\n",
      "Using cached scipy_stubs-1.16.1.1-py3-none-any.whl (553 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tifffile-2025.8.28-py3-none-any.whl (231 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m138.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m161.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m166.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m179.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m173.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m173.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m174.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m165.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m168.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m168.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m180.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m158.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tornado-6.5.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Downloading statsmodels-0.14.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m167.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m171.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: webencodings, wcwidth, pytz, pure_eval, ptyprocess, nvidia-cusparselt-cu12, mpmath, fastjsonschema, widgetsnbextension, websocket-client, webcolors, urllib3, uri-template, tzdata, typing_extensions, types-python-dateutil, triton, traitlets, tqdm, tornado, tinycss2, threadpoolctl, sympy, soupsieve, sniffio, six, Send2Trash, rpds-py, rfc3986-validator, pyzmq, PyYAML, python-json-logger, pyparsing, Pygments, pycparser, pyarrow, psutil, prompt_toolkit, prometheus_client, platformdirs, pillow, pexpect, parso, pandocfilters, packaging, overrides, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nest-asyncio, mistune, MarkupSafe, lark, kiwisolver, jupyterlab_widgets, jupyterlab_pygments, jsonpointer, json5, joblib, idna, h11, fsspec, fqdn, fonttools, filelock, executing, defusedxml, decorator, debugpy, cycler, comm, charset-normalizer, certifi, bleach, babel, attrs, async-lru, asttokens, appnope, tifffile, terminado, stack-data, scipy, rfc3987-syntax, rfc3339-validator, requests, referencing, python-dateutil, pandas-stubs, opencv-python, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, matplotlib-inline, lazy_loader, jupyter_core, Jinja2, jedi, ipython_pygments_lexers, imageio, httpcore, contourpy, cffi, beautifulsoup4, anyio, scikit-learn, scikit-image, pandas, nvidia-cusolver-cu12, matplotlib, jupyter_server_terminals, jupyter_client, jsonschema-specifications, ipython, httpx, arrow, argon2-cffi-bindings, torch, statsmodels, seaborn, scipy-stubs, jsonschema, isoduration, ipywidgets, ipykernel, argon2-cffi, torchvision, nbformat, jupyter-console, nbclient, jupyter-events, nbconvert, jupyter_server, notebook_shim, jupyterlab_server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.3\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.3:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.61:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufile-cu12\n",
      "    Found existing installation: nvidia-cufile-cu12 1.13.0.11\n",
      "    Uninstalling nvidia-cufile-cu12-1.13.0.11:\n",
      "      Successfully uninstalled nvidia-cufile-cu12-1.13.0.11\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0.dev20250319+cu128 requires torch==2.8.0.dev20250319, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 PyYAML-6.0.2 Pygments-2.19.2 Send2Trash-1.8.3 anyio-4.10.0 appnope-0.1.4 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.3.0 asttokens-3.0.0 async-lru-2.0.5 attrs-25.3.0 babel-2.17.0 beautifulsoup4-4.13.5 bleach-6.2.0 certifi-2025.8.3 cffi-1.17.1 charset-normalizer-3.4.3 comm-0.2.3 contourpy-1.3.3 cycler-0.12.1 debugpy-1.8.16 decorator-5.2.1 defusedxml-0.7.1 executing-2.2.1 fastjsonschema-2.21.2 filelock-3.19.1 fonttools-4.59.2 fqdn-1.5.1 fsspec-2025.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 imageio-2.37.0 ipykernel-6.30.1 ipython-9.5.0 ipython_pygments_lexers-1.1.1 ipywidgets-8.1.7 isoduration-20.11.0 jedi-0.19.2 joblib-1.5.2 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.4.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter_client-8.6.3 jupyter_core-5.8.1 jupyter_server-2.17.0 jupyter_server_terminals-0.5.3 jupyterlab-4.4.6 jupyterlab_pygments-0.3.0 jupyterlab_server-2.27.3 jupyterlab_widgets-3.0.15 kiwisolver-1.4.9 lark-1.2.2 lazy_loader-0.4 matplotlib-3.10.6 matplotlib-inline-0.1.7 mistune-3.1.4 mpmath-1.3.0 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 nest-asyncio-1.6.0 networkx-3.5 notebook-7.4.5 notebook_shim-0.2.4 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 opencv-python-4.12.0.88 overrides-7.7.0 packaging-25.0 pandas-2.3.2 pandas-stubs-2.3.2.250827 pandocfilters-1.5.1 parso-0.8.5 pexpect-4.9.0 pillow-11.3.0 platformdirs-4.4.0 prometheus_client-0.22.1 prompt_toolkit-3.0.52 psutil-7.0.0 ptyprocess-0.7.0 pure_eval-0.2.3 pyarrow-21.0.0 pycparser-2.22 pyparsing-3.2.3 python-dateutil-2.9.0.post0 python-json-logger-3.3.0 pytz-2025.2 pyzmq-27.0.2 referencing-0.36.2 requests-2.32.5 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.27.1 scikit-image-0.25.2 scikit-learn-1.7.1 scipy-1.16.1 scipy-stubs-1.16.1.1 seaborn-0.13.2 six-1.17.0 sniffio-1.3.1 soupsieve-2.8 stack-data-0.6.3 statsmodels-0.14.5 sympy-1.14.0 terminado-0.18.1 threadpoolctl-3.6.0 tifffile-2025.8.28 tinycss2-1.4.0 torch-2.8.0 torchvision-0.23.0 tornado-6.5.2 tqdm-4.67.1 traitlets-5.14.3 triton-3.4.0 types-python-dateutil-2.9.0.20250822 typing_extensions-4.15.0 tzdata-2025.2 uri-template-1.3.0 urllib3-2.5.0 wcwidth-0.2.13 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:30:02,609 - INFO - RQ3 Complete Pipeline - GPU Accelerated - Initialized Successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 RQ3 Pipeline initialized on cuda\n",
      "   GPU: NVIDIA RTX A6000\n",
      "   Memory: 50.9 GB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import jaccard_score, f1_score, precision_score, recall_score\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "import logging\n",
    "\n",
    "# Setup paths\n",
    "project_root = Path('/workspace/HistoPathologyResearch/')\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import custom modules\n",
    "from preprocessing.vahadane_gpu import GPUVahadaneNormalizer\n",
    "from models.unet_rq3 import UNetRQ3, create_unet_rq3  # RQ3-specific U-Net (separate from RQ2)\n",
    "from utils.metrics import calculate_segmentation_metrics\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('../artifacts/rq3/logs/rq3_pipeline.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set style and warnings\n",
    "plt.style.use('seaborn-v0_8') if 'seaborn-v0_8' in plt.style.available else plt.style.use('seaborn')\n",
    "sns.set_palette('husl')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 RQ3 Pipeline initialized on {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Create artifacts directories\n",
    "artifacts_dir = project_root / 'artifacts' / 'rq3'\n",
    "for subdir in ['checkpoints', 'results', 'datasets', 'plots', 'logs']:\n",
    "    (artifacts_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(\"RQ3 Complete Pipeline - GPU Accelerated - Initialized Successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Analysis and Preparation\n",
    "\n",
    "### 1.1 Identify Top 5 Tissues by Sample Count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:30:15,690 - INFO - Analyzing dataset to identify top 5 tissues...\n",
      "2025-09-03 17:30:22,204 - INFO - Selected 5 tissues with 5,072 total images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Dataset Analysis Results:\n",
      "==================================================\n",
      "✅ Breast         : 2,351 images\n",
      "✅ Colon          : 1,440 images\n",
      "✅ Adrenal_gland  : 437 images\n",
      "✅ Esophagus      : 424 images\n",
      "✅ Bile-duct      : 420 images\n",
      "\n",
      "🎯 Selected Top 5 Tissues for RQ3:\n",
      "1. Breast: 2,351 images\n",
      "2. Colon: 1,440 images\n",
      "3. Adrenal_gland: 437 images\n",
      "4. Esophagus: 424 images\n",
      "5. Bile-duct: 420 images\n",
      "\n",
      "📊 Total images in top 5 tissues: 5,072\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATASET ANALYSIS - TOP 5 TISSUES\n",
    "# =============================================================================\n",
    "\n",
    "dataset_path = project_root / 'dataset_tissues'\n",
    "logger.info(\"Analyzing dataset to identify top 5 tissues...\")\n",
    "\n",
    "# Count images per tissue\n",
    "tissue_counts = {}\n",
    "tissue_paths = {}\n",
    "\n",
    "for tissue_dir in dataset_path.iterdir():\n",
    "    if tissue_dir.is_dir():\n",
    "        tissue_name = tissue_dir.name\n",
    "        total_count = 0\n",
    "        paths = {'train': [], 'test': [], 'val': []}\n",
    "        \n",
    "        for split in ['train', 'test', 'val']:\n",
    "            images_dir = tissue_dir / split / 'images'\n",
    "            masks_dir = tissue_dir / split / 'sem_masks'  # Semantic masks\n",
    "            \n",
    "            if images_dir.exists() and masks_dir.exists():\n",
    "                image_files = list(images_dir.glob('*.png'))\n",
    "                mask_files = list(masks_dir.glob('*.png'))\n",
    "                \n",
    "                # Only count images that have corresponding masks\n",
    "                valid_pairs = []\n",
    "                for img_file in image_files:\n",
    "                    mask_file = masks_dir / img_file.name.replace('img_', 'sem_')\n",
    "                    if mask_file.exists():\n",
    "                        valid_pairs.append((img_file, mask_file))\n",
    "                \n",
    "                paths[split] = valid_pairs\n",
    "                total_count += len(valid_pairs)\n",
    "        \n",
    "        tissue_counts[tissue_name] = total_count\n",
    "        tissue_paths[tissue_name] = paths\n",
    "\n",
    "# Sort tissues by count and select top 5\n",
    "top_5_tissues = sorted(tissue_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "selected_tissues = [tissue for tissue, count in top_5_tissues]\n",
    "\n",
    "print(\"🔍 Dataset Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "for tissue, count in sorted(tissue_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    marker = \"✅\" if tissue in selected_tissues else \"  \"\n",
    "    print(f\"{marker} {tissue:15}: {count:,} images\")\n",
    "\n",
    "print(f\"\\n🎯 Selected Top 5 Tissues for RQ3:\")\n",
    "for i, (tissue, count) in enumerate(top_5_tissues, 1):\n",
    "    print(f\"{i}. {tissue}: {count:,} images\")\n",
    "\n",
    "total_selected = sum(count for _, count in top_5_tissues)\n",
    "print(f\"\\n📊 Total images in top 5 tissues: {total_selected:,}\")\n",
    "\n",
    "# Save tissue selection metadata\n",
    "tissue_metadata = {\n",
    "    'selected_tissues': selected_tissues,\n",
    "    'tissue_counts': dict(top_5_tissues),\n",
    "    'total_images': total_selected,\n",
    "    'selection_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'selection_criteria': 'Top 5 tissues by image count'\n",
    "}\n",
    "\n",
    "with open(artifacts_dir / 'results' / 'tissue_selection.json', 'w') as f:\n",
    "    json.dump(tissue_metadata, f, indent=2)\n",
    "\n",
    "logger.info(f\"Selected {len(selected_tissues)} tissues with {total_selected:,} total images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create Small Sample for Testing\n",
    "\n",
    "Before processing the full dataset, let's create a small sample to test the pipeline and ensure everything works correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:30:36,197 - INFO - Sample configuration created: 75 images across 5 tissues\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Running in TESTING mode\n",
      "   Sample size: 5 images per tissue per split\n",
      "📁 Breast          train:   5 images\n",
      "📁 Breast          test :   5 images\n",
      "📁 Breast          val  :   5 images\n",
      "📁 Colon           train:   5 images\n",
      "📁 Colon           test :   5 images\n",
      "📁 Colon           val  :   5 images\n",
      "📁 Adrenal_gland   train:   5 images\n",
      "📁 Adrenal_gland   test :   5 images\n",
      "📁 Adrenal_gland   val  :   5 images\n",
      "📁 Esophagus       train:   5 images\n",
      "📁 Esophagus       test :   5 images\n",
      "📁 Esophagus       val  :   5 images\n",
      "📁 Bile-duct       train:   5 images\n",
      "📁 Bile-duct       test :   5 images\n",
      "📁 Bile-duct       val  :   5 images\n",
      "\n",
      "📊 Total sample images: 75\n",
      "🎯 Expected processing time: 0.0 minutes (GPU)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CREATE TEST SAMPLE\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration for testing vs production\n",
    "TESTING_MODE = True  # Set to False for full dataset processing\n",
    "SAMPLE_SIZE_PER_TISSUE = 5 if TESTING_MODE else None  # None means use all images\n",
    "\n",
    "print(f\"🧪 Running in {'TESTING' if TESTING_MODE else 'PRODUCTION'} mode\")\n",
    "if TESTING_MODE:\n",
    "    print(f\"   Sample size: {SAMPLE_SIZE_PER_TISSUE} images per tissue per split\")\n",
    "\n",
    "# Create sample dataset for testing\n",
    "sample_data = {}\n",
    "total_sample_images = 0\n",
    "\n",
    "for tissue in selected_tissues:\n",
    "    sample_data[tissue] = {'train': [], 'test': [], 'val': []}\n",
    "    \n",
    "    for split in ['train', 'test', 'val']:\n",
    "        available_pairs = tissue_paths[tissue][split]\n",
    "        \n",
    "        if TESTING_MODE and SAMPLE_SIZE_PER_TISSUE:\n",
    "            # Take a small sample for testing\n",
    "            selected_pairs = available_pairs[:SAMPLE_SIZE_PER_TISSUE]\n",
    "        else:\n",
    "            # Use all available data\n",
    "            selected_pairs = available_pairs\n",
    "        \n",
    "        sample_data[tissue][split] = selected_pairs\n",
    "        total_sample_images += len(selected_pairs)\n",
    "        \n",
    "        print(f\"📁 {tissue:15} {split:5}: {len(selected_pairs):3} images\")\n",
    "\n",
    "print(f\"\\n📊 Total sample images: {total_sample_images:,}\")\n",
    "print(f\"🎯 Expected processing time: {total_sample_images * 0.001 / 60:.1f} minutes (GPU)\")\n",
    "\n",
    "# Save sample configuration\n",
    "sample_config = {\n",
    "    'testing_mode': TESTING_MODE,\n",
    "    'sample_size_per_tissue': SAMPLE_SIZE_PER_TISSUE,\n",
    "    'total_sample_images': total_sample_images,\n",
    "    'tissues': selected_tissues,\n",
    "    'splits': ['train', 'test', 'val']\n",
    "}\n",
    "\n",
    "with open(artifacts_dir / 'results' / 'sample_config.json', 'w') as f:\n",
    "    json.dump(sample_config, f, indent=2)\n",
    "\n",
    "logger.info(f\"Sample configuration created: {total_sample_images} images across {len(selected_tissues)} tissues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU-Accelerated Vahadane Stain Normalization\n",
    "\n",
    "### 2.1 Initialize GPU Normalizer and Select Target Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:30:45,488 - INFO - Initializing GPU-accelerated Vahadane normalizer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 GPUVahadaneNormalizer initialized on cuda\n",
      "   GPU: NVIDIA RTX A6000\n",
      "   Memory: 50.9 GB\n",
      "✅ GPU Vahadane normalizer initialized on cuda\n",
      "🎯 Evaluating images for optimal target selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:30:46,527 - INFO - Target image selected: Adrenal_gland with quality score 49.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n🏆 Selected target image:\n",
      "   Tissue: Adrenal_gland\n",
      "   Split: val\n",
      "   Quality score: 49.31\n",
      "   Tissue coverage: 0.96\n",
      "   Contrast: 0.17\n",
      "\\n🔧 Fitting normalizer to target image...\n",
      "🎯 Fitting normalizer to target image (shape: torch.Size([256, 256, 3]))\n",
      "✓ GPU Vahadane normalizer fitted successfully\n",
      "  Target stain matrix shape: torch.Size([2, 3])\n",
      "  Hematoxylin vector: [0.2794522 0.8148201 0.5079122]\n",
      "  Eosin vector: [ 0.83799344  0.05124305 -0.543269  ]\n",
      "✅ Normalizer fitted successfully in 0.733s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:30:47,262 - INFO - GPU normalizer fitted in 0.733s\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GPU VAHADANE STAIN NORMALIZATION SETUP\n",
    "# =============================================================================\n",
    "\n",
    "logger.info(\"Initializing GPU-accelerated Vahadane normalizer...\")\n",
    "\n",
    "# Initialize GPU normalizer with optimal settings\n",
    "gpu_normalizer = GPUVahadaneNormalizer(\n",
    "    batch_size=16,  # Adjust based on GPU memory\n",
    "    device=device,\n",
    "    memory_efficient=True,\n",
    "    threshold=0.8,\n",
    "    lambda1=0.1,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "print(f\"✅ GPU Vahadane normalizer initialized on {device}\")\n",
    "\n",
    "# Function to evaluate image quality for target selection\n",
    "def evaluate_image_quality_gpu(image_tensor):\n",
    "    \"\"\"Evaluate image quality using GPU-accelerated metrics\"\"\"\n",
    "    if len(image_tensor.shape) == 3:\n",
    "        image_tensor = image_tensor.unsqueeze(0)\n",
    "    \n",
    "    img = image_tensor.float() / 255.0\n",
    "    \n",
    "    # Tissue coverage (non-white pixels)\n",
    "    gray = torch.mean(img, dim=-1)\n",
    "    tissue_mask = gray < 0.8\n",
    "    tissue_coverage = torch.mean(tissue_mask.float())\n",
    "    \n",
    "    # Contrast (standard deviation)\n",
    "    contrast = torch.std(gray)\n",
    "    \n",
    "    # Color distribution\n",
    "    color_std = torch.std(img, dim=(1, 2))\n",
    "    color_balance = torch.mean(color_std)\n",
    "    \n",
    "    # Combined quality score\n",
    "    quality_score = (\n",
    "        tissue_coverage * 40 +\n",
    "        contrast * 30 +\n",
    "        color_balance * 30\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'quality_score': quality_score.item(),\n",
    "        'tissue_coverage': tissue_coverage.item(),\n",
    "        'contrast': contrast.item(),\n",
    "        'color_balance': color_balance.item()\n",
    "    }\n",
    "\n",
    "# Select best target image from sample data\n",
    "print(\"🎯 Evaluating images for optimal target selection...\")\n",
    "target_candidates = []\n",
    "\n",
    "for tissue in selected_tissues:\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        for img_path, mask_path in sample_data[tissue][split][:2]:  # Check first 2 from each split\n",
    "            try:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img_tensor = torch.from_numpy(img).to(device)\n",
    "                    \n",
    "                    quality_metrics = evaluate_image_quality_gpu(img_tensor)\n",
    "                    \n",
    "                    target_candidates.append({\n",
    "                        'tissue': tissue,\n",
    "                        'split': split,\n",
    "                        'path': img_path,\n",
    "                        'image': img,\n",
    "                        **quality_metrics\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to evaluate {img_path}: {e}\")\n",
    "\n",
    "# Select best target\n",
    "if target_candidates:\n",
    "    target_candidates.sort(key=lambda x: x['quality_score'], reverse=True)\n",
    "    best_target = target_candidates[0]\n",
    "    \n",
    "    print(f\"\\\\n🏆 Selected target image:\")\n",
    "    print(f\"   Tissue: {best_target['tissue']}\")\n",
    "    print(f\"   Split: {best_target['split']}\")\n",
    "    print(f\"   Quality score: {best_target['quality_score']:.2f}\")\n",
    "    print(f\"   Tissue coverage: {best_target['tissue_coverage']:.2f}\")\n",
    "    print(f\"   Contrast: {best_target['contrast']:.2f}\")\n",
    "    \n",
    "    target_image = best_target['image']\n",
    "    target_info = best_target\n",
    "    \n",
    "    # Save target image\n",
    "    target_save_path = artifacts_dir / 'results' / 'target_image.png'\n",
    "    Image.fromarray(target_image).save(target_save_path)\n",
    "    \n",
    "    # Save target metadata\n",
    "    target_metadata = {k: v for k, v in target_info.items() if k != 'image'}\n",
    "    target_metadata['path'] = str(target_metadata['path'])\n",
    "    \n",
    "    with open(artifacts_dir / 'results' / 'target_metadata.json', 'w') as f:\n",
    "        json.dump(target_metadata, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"Target image selected: {best_target['tissue']} with quality score {best_target['quality_score']:.2f}\")\n",
    "else:\n",
    "    raise ValueError(\"No valid target candidates found!\")\n",
    "\n",
    "# Test normalizer with target\n",
    "print(f\"\\\\n🔧 Fitting normalizer to target image...\")\n",
    "start_time = time.time()\n",
    "gpu_normalizer.fit(target_image)\n",
    "fit_time = time.time() - start_time\n",
    "\n",
    "print(f\"✅ Normalizer fitted successfully in {fit_time:.3f}s\")\n",
    "logger.info(f\"GPU normalizer fitted in {fit_time:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Apply Normalization to Sample Dataset\n",
    "\n",
    "Process all sample images with GPU-accelerated batch normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:31:01,859 - INFO - Starting batch normalization of sample dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n🔄 Processing Breast...\n",
      "   train: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.244s\n",
      "   test: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.206s\n",
      "   val: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.245s\n",
      "   ✅ Breast: 15 processed, 0 failed\n",
      "\\n🔄 Processing Colon...\n",
      "   train: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.204s\n",
      "   test: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.234s\n",
      "   val: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.203s\n",
      "   ✅ Colon: 15 processed, 0 failed\n",
      "\\n🔄 Processing Adrenal_gland...\n",
      "   train: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.199s\n",
      "   test: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.216s\n",
      "   val: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.207s\n",
      "   ✅ Adrenal_gland: 15 processed, 0 failed\n",
      "\\n🔄 Processing Esophagus...\n",
      "   train: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.231s\n",
      "   test: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.201s\n",
      "   val: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.215s\n",
      "   ✅ Esophagus: 15 processed, 0 failed\n",
      "\\n🔄 Processing Bile-duct...\n",
      "   train: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.205s\n",
      "   test: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n",
      "      Batch 1: 5 images in 0.207s\n",
      "   val: 5 images\n",
      "🔄 Processing batch of 5 images on GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:31:17,995 - INFO - Normalization completed: 75 images processed in 15.79s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Batch 1: 5 images in 0.193s\n",
      "   ✅ Bile-duct: 15 processed, 0 failed\n",
      "\\n🎉 Normalization Complete!\n",
      "   📊 Processed: 75 images\n",
      "   ❌ Failed: 0 images\n",
      "   ⏱️  Total time: 15.79s\n",
      "   ⚡ Speed: 4.8 images/sec\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BATCH NORMALIZATION PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "logger.info(\"Starting batch normalization of sample dataset...\")\n",
    "\n",
    "# Create directories for normalized datasets\n",
    "normalized_base = artifacts_dir / 'datasets' / 'normalized'\n",
    "original_base = artifacts_dir / 'datasets' / 'original'\n",
    "\n",
    "for base_dir in [normalized_base, original_base]:\n",
    "    for tissue in selected_tissues:\n",
    "        for split in ['train', 'test', 'val']:\n",
    "            (base_dir / tissue / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "            (base_dir / tissue / split / 'masks').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process images in batches\n",
    "normalization_results = {}\n",
    "processing_stats = {\n",
    "    'total_processed': 0,\n",
    "    'total_failed': 0,\n",
    "    'processing_time': 0,\n",
    "    'tissues_processed': {}\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for tissue in selected_tissues:\n",
    "    print(f\"\\\\n🔄 Processing {tissue}...\")\n",
    "    tissue_results = {'train': [], 'test': [], 'val': []}\n",
    "    tissue_stats = {'processed': 0, 'failed': 0}\n",
    "    \n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_pairs = sample_data[tissue][split]\n",
    "        if not split_pairs:\n",
    "            continue\n",
    "            \n",
    "        print(f\"   {split}: {len(split_pairs)} images\")\n",
    "        \n",
    "        # Process in batches for GPU efficiency\n",
    "        batch_size = min(8, len(split_pairs))  # Adjust based on memory\n",
    "        \n",
    "        for i in range(0, len(split_pairs), batch_size):\n",
    "            batch_pairs = split_pairs[i:i+batch_size]\n",
    "            batch_images = []\n",
    "            batch_masks = []\n",
    "            batch_metadata = []\n",
    "            \n",
    "            # Load batch\n",
    "            for img_path, mask_path in batch_pairs:\n",
    "                try:\n",
    "                    # Load image\n",
    "                    img = cv2.imread(str(img_path))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Load mask\n",
    "                    mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "                    \n",
    "                    batch_images.append(img)\n",
    "                    batch_masks.append(mask)\n",
    "                    batch_metadata.append({\n",
    "                        'tissue': tissue,\n",
    "                        'split': split,\n",
    "                        'original_img_path': str(img_path),\n",
    "                        'original_mask_path': str(mask_path),\n",
    "                        'filename': img_path.name\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to load {img_path}: {e}\")\n",
    "                    tissue_stats['failed'] += 1\n",
    "                    processing_stats['total_failed'] += 1\n",
    "            \n",
    "            if not batch_images:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Apply normalization to batch\n",
    "                batch_start = time.time()\n",
    "                normalized_batch = gpu_normalizer.transform_batch(batch_images)\n",
    "                batch_time = time.time() - batch_start\n",
    "                \n",
    "                # Save results\n",
    "                for j, (orig_img, norm_img, mask, metadata) in enumerate(\n",
    "                    zip(batch_images, normalized_batch, batch_masks, batch_metadata)\n",
    "                ):\n",
    "                    # Generate unique filename\n",
    "                    base_name = f\"{tissue}_{split}_{i+j:04d}\"\n",
    "                    \n",
    "                    # Save original\n",
    "                    orig_img_path = original_base / tissue / split / 'images' / f\"{base_name}.png\"\n",
    "                    orig_mask_path = original_base / tissue / split / 'masks' / f\"{base_name}.png\"\n",
    "                    \n",
    "                    Image.fromarray(orig_img).save(orig_img_path)\n",
    "                    Image.fromarray(mask).save(orig_mask_path)\n",
    "                    \n",
    "                    # Save normalized\n",
    "                    norm_img_path = normalized_base / tissue / split / 'images' / f\"{base_name}.png\"\n",
    "                    norm_mask_path = normalized_base / tissue / split / 'masks' / f\"{base_name}.png\"\n",
    "                    \n",
    "                    Image.fromarray(norm_img).save(norm_img_path)\n",
    "                    Image.fromarray(mask).save(norm_mask_path)  # Same mask for both\n",
    "                    \n",
    "                    # Store metadata\n",
    "                    result_metadata = {\n",
    "                        **metadata,\n",
    "                        'normalized_img_path': str(norm_img_path),\n",
    "                        'normalized_mask_path': str(norm_mask_path),\n",
    "                        'original_saved_img_path': str(orig_img_path),\n",
    "                        'original_saved_mask_path': str(orig_mask_path),\n",
    "                        'processing_time': batch_time / len(batch_images),\n",
    "                        'base_name': base_name\n",
    "                    }\n",
    "                    \n",
    "                    tissue_results[split].append(result_metadata)\n",
    "                    tissue_stats['processed'] += 1\n",
    "                    processing_stats['total_processed'] += 1\n",
    "                \n",
    "                print(f\"      Batch {i//batch_size + 1}: {len(batch_images)} images in {batch_time:.3f}s\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Batch normalization failed: {e}\")\n",
    "                tissue_stats['failed'] += len(batch_images)\n",
    "                processing_stats['total_failed'] += len(batch_images)\n",
    "    \n",
    "    normalization_results[tissue] = tissue_results\n",
    "    processing_stats['tissues_processed'][tissue] = tissue_stats\n",
    "    \n",
    "    print(f\"   ✅ {tissue}: {tissue_stats['processed']} processed, {tissue_stats['failed']} failed\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "processing_stats['processing_time'] = total_time\n",
    "\n",
    "# Summary\n",
    "print(f\"\\\\n🎉 Normalization Complete!\")\n",
    "print(f\"   📊 Processed: {processing_stats['total_processed']} images\")\n",
    "print(f\"   ❌ Failed: {processing_stats['total_failed']} images\")\n",
    "print(f\"   ⏱️  Total time: {total_time:.2f}s\")\n",
    "print(f\"   ⚡ Speed: {processing_stats['total_processed']/total_time:.1f} images/sec\")\n",
    "\n",
    "# Save processing results\n",
    "with open(artifacts_dir / 'results' / 'normalization_results.json', 'w') as f:\n",
    "    json.dump(normalization_results, f, indent=2, default=str)\n",
    "\n",
    "with open(artifacts_dir / 'results' / 'processing_stats.json', 'w') as f:\n",
    "    json.dump(processing_stats, f, indent=2)\n",
    "\n",
    "logger.info(f\"Normalization completed: {processing_stats['total_processed']} images processed in {total_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Evaluation\n",
    "\n",
    "### 3.1 Create Dataset Classes and DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Creating dataloaders...\n",
      "   original train: 25 images\n",
      "   original val: 25 images\n",
      "   normalized train: 25 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:32:04,293 - INFO - Dataloaders created successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   normalized val: 25 images\n",
      "✅ Dataloaders created:\n",
      "   original:\n",
      "     train: 7 batches, 25 images\n",
      "     val: 7 batches, 25 images\n",
      "   normalized:\n",
      "     train: 7 batches, 25 images\n",
      "     val: 7 batches, 25 images\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATASET CLASSES AND DATALOADERS\n",
    "# =============================================================================\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    \"\"\"Dataset class for nuclei segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = sorted(list(self.image_dir.glob('*.png')))\n",
    "        self.mask_files = sorted(list(self.mask_dir.glob('*.png')))\n",
    "        \n",
    "        # Ensure we have matching pairs\n",
    "        assert len(self.image_files) == len(self.mask_files), \\\n",
    "            f\"Mismatch: {len(self.image_files)} images, {len(self.mask_files)} masks\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_files[idx]\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load mask\n",
    "        mask_path = self.mask_files[idx]\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = torch.from_numpy(mask).long()\n",
    "        else:\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "            mask = torch.from_numpy(mask).long()\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders for both original and normalized data\n",
    "def create_dataloaders(data_type='original', batch_size=4, num_workers=2):\n",
    "    \"\"\"Create dataloaders for specified data type (original or normalized)\"\"\"\n",
    "    \n",
    "    base_dir = artifacts_dir / 'datasets' / data_type\n",
    "    dataloaders = {}\n",
    "    \n",
    "    for split in ['train', 'val']:  # Skip test for now, use val for evaluation\n",
    "        # Combine all tissues for the split\n",
    "        all_images = []\n",
    "        all_masks = []\n",
    "        \n",
    "        for tissue in selected_tissues:\n",
    "            tissue_img_dir = base_dir / tissue / split / 'images'\n",
    "            tissue_mask_dir = base_dir / tissue / split / 'masks'\n",
    "            \n",
    "            if tissue_img_dir.exists() and tissue_mask_dir.exists():\n",
    "                tissue_images = list(tissue_img_dir.glob('*.png'))\n",
    "                tissue_masks = list(tissue_mask_dir.glob('*.png'))\n",
    "                \n",
    "                all_images.extend(tissue_images)\n",
    "                all_masks.extend(tissue_masks)\n",
    "        \n",
    "        if not all_images:\n",
    "            continue\n",
    "        \n",
    "        print(f\"   {data_type} {split}: {len(all_images)} images\")\n",
    "        \n",
    "        # Create temporary combined directory structure\n",
    "        temp_dir = artifacts_dir / 'temp' / data_type / split\n",
    "        temp_img_dir = temp_dir / 'images'\n",
    "        temp_mask_dir = temp_dir / 'masks'\n",
    "        temp_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        temp_mask_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy files to temporary structure (just create symlinks for efficiency)\n",
    "        for i, (img_file, mask_file) in enumerate(zip(all_images, all_masks)):\n",
    "            temp_img_file = temp_img_dir / f\"{i:04d}.png\"\n",
    "            temp_mask_file = temp_mask_dir / f\"{i:04d}.png\"\n",
    "            \n",
    "            # Create symlinks or copy files\n",
    "            if not temp_img_file.exists():\n",
    "                try:\n",
    "                    temp_img_file.symlink_to(img_file.absolute())\n",
    "                    temp_mask_file.symlink_to(mask_file.absolute())\n",
    "                except:\n",
    "                    # Fallback to copying if symlinks fail\n",
    "                    import shutil\n",
    "                    shutil.copy2(img_file, temp_img_file)\n",
    "                    shutil.copy2(mask_file, temp_mask_file)\n",
    "        \n",
    "        # Create dataset\n",
    "        transform = train_transform if split == 'train' else val_transform\n",
    "        dataset = SegmentationDataset(temp_img_dir, temp_mask_dir, transform=transform)\n",
    "        \n",
    "        # Create dataloader\n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=(split == 'train'),\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        dataloaders[split] = dataloader\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "# Create dataloaders\n",
    "print(\"📊 Creating dataloaders...\")\n",
    "original_dataloaders = create_dataloaders('original', batch_size=4)\n",
    "normalized_dataloaders = create_dataloaders('normalized', batch_size=4)\n",
    "\n",
    "print(f\"✅ Dataloaders created:\")\n",
    "for data_type, loaders in [('original', original_dataloaders), ('normalized', normalized_dataloaders)]:\n",
    "    print(f\"   {data_type}:\")\n",
    "    for split, loader in loaders.items():\n",
    "        print(f\"     {split}: {len(loader)} batches, {len(loader.dataset)} images\")\n",
    "\n",
    "logger.info(\"Dataloaders created successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train U-Net Models\n",
    "\n",
    "Train separate U-Net models on original and normalized data for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n🚀 Training unet_original model...\n",
      "✅ UNet-RQ3 created for RQ3:\n",
      "   Purpose: Stain normalization impact study\n",
      "   Parameters: 13,395,654\n",
      "   Model size: 51.13 MB\n",
      "   Input channels: 3\n",
      "   Output classes: 6\n",
      "   Device: cuda\n",
      "   🔒 Separate from RQ2 U-Net to preserve existing results\n",
      "\\n📅 Epoch 1/3\n",
      "   Batch 1/7: Loss = 4.0689\n",
      "   Batch 6/7: Loss = 2.4303\n",
      "   📊 Train Loss: 3.1089, Val Loss: 1.3150\n",
      "   📈 Train Dice: 0.2241, Val Dice: 0.2893\n",
      "   💾 Best model saved (Val Loss: 1.3150)\n",
      "\\n📅 Epoch 2/3\n",
      "   Batch 1/7: Loss = 2.7177\n",
      "   Batch 6/7: Loss = 1.7089\n",
      "   📊 Train Loss: 2.1027, Val Loss: 1.5390\n",
      "   📈 Train Dice: 0.3142, Val Dice: 0.2575\n",
      "\\n📅 Epoch 3/3\n",
      "   Batch 1/7: Loss = 1.8523\n",
      "   Batch 6/7: Loss = 1.3585\n",
      "   📊 Train Loss: 1.6067, Val Loss: 1.1599\n",
      "   📈 Train Dice: 0.3934, Val Dice: 0.3506\n",
      "   💾 Best model saved (Val Loss: 1.1599)\n",
      "✅ unet_original training completed!\n",
      "\\n🚀 Training unet_normalized model...\n",
      "✅ UNet-RQ3 created for RQ3:\n",
      "   Purpose: Stain normalization impact study\n",
      "   Parameters: 13,395,654\n",
      "   Model size: 51.13 MB\n",
      "   Input channels: 3\n",
      "   Output classes: 6\n",
      "   Device: cuda\n",
      "   🔒 Separate from RQ2 U-Net to preserve existing results\n",
      "\\n📅 Epoch 1/3\n",
      "   Batch 1/7: Loss = 4.3602\n",
      "   Batch 6/7: Loss = 2.6255\n",
      "   📊 Train Loss: 3.0652, Val Loss: 1.7247\n",
      "   📈 Train Dice: 0.2035, Val Dice: 0.1885\n",
      "   💾 Best model saved (Val Loss: 1.7247)\n",
      "\\n📅 Epoch 2/3\n",
      "   Batch 1/7: Loss = 2.0480\n",
      "   Batch 6/7: Loss = 1.7232\n",
      "   📊 Train Loss: 1.8030, Val Loss: 1.5235\n",
      "   📈 Train Dice: 0.3956, Val Dice: 0.3072\n",
      "   💾 Best model saved (Val Loss: 1.5235)\n",
      "\\n📅 Epoch 3/3\n",
      "   Batch 1/7: Loss = 1.4666\n",
      "   Batch 6/7: Loss = 1.2528\n",
      "   📊 Train Loss: 1.4345, Val Loss: 1.0181\n",
      "   📈 Train Dice: 0.4426, Val Dice: 0.4070\n",
      "   💾 Best model saved (Val Loss: 1.0181)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:32:46,486 - INFO - Model training completed: 2 models trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ unet_normalized training completed!\n",
      "\\n🎉 All models trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODEL TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "from src.models.unet_rq3 import create_unet_rq3\n",
    "from src.utils.metrics import calculate_batch_metrics, evaluate_model_on_dataset\n",
    "\n",
    "def train_model(dataloaders, model_name, epochs=5, learning_rate=1e-4):\n",
    "    \"\"\"Train a U-Net model and return training history\"\"\"\n",
    "    \n",
    "    print(f\"\\\\n🚀 Training {model_name} model...\")\n",
    "    \n",
    "    # Create RQ3-specific model (separate from RQ2)\n",
    "    model = create_unet_rq3(n_channels=3, n_classes=6, device=device)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=255)  # Ignore unknown pixels\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_metrics': [],\n",
    "        'val_metrics': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\\\n📅 Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_metrics_list = []\n",
    "        \n",
    "        for batch_idx, (images, masks) in enumerate(dataloaders['train']):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics for this batch\n",
    "            with torch.no_grad():\n",
    "                predictions = torch.argmax(outputs, dim=1)\n",
    "                batch_metrics = calculate_batch_metrics(predictions, masks, num_classes=6)\n",
    "                train_metrics_list.append(batch_metrics)\n",
    "            \n",
    "            if batch_idx % 5 == 0:  # Print every 5 batches\n",
    "                print(f\"   Batch {batch_idx+1}/{len(dataloaders['train'])}: Loss = {loss.item():.4f}\")\n",
    "        \n",
    "        # Average training metrics\n",
    "        avg_train_loss = train_loss / len(dataloaders['train'])\n",
    "        avg_train_metrics = {}\n",
    "        for key in train_metrics_list[0].keys():\n",
    "            avg_train_metrics[key] = np.mean([m[key] for m in train_metrics_list if not np.isnan(m[key])])\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in dataloaders['val']:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Calculate metrics\n",
    "                predictions = torch.argmax(outputs, dim=1)\n",
    "                batch_metrics = calculate_batch_metrics(predictions, masks, num_classes=6)\n",
    "                val_metrics_list.append(batch_metrics)\n",
    "        \n",
    "        avg_val_loss = val_loss / len(dataloaders['val'])\n",
    "        avg_val_metrics = {}\n",
    "        for key in val_metrics_list[0].keys():\n",
    "            avg_val_metrics[key] = np.mean([m[key] for m in val_metrics_list if not np.isnan(m[key])])\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['train_metrics'].append(avg_train_metrics)\n",
    "        history['val_metrics'].append(avg_val_metrics)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"   📊 Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"   📈 Train Dice: {avg_train_metrics.get('avg_dice', 0):.4f}, Val Dice: {avg_val_metrics.get('avg_dice', 0):.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), artifacts_dir / 'checkpoints' / f'{model_name}_best.pth')\n",
    "            print(f\"   💾 Best model saved (Val Loss: {best_val_loss:.4f})\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), artifacts_dir / 'checkpoints' / f'{model_name}_final.pth')\n",
    "    \n",
    "    # Save training history\n",
    "    with open(artifacts_dir / 'results' / f'{model_name}_history.json', 'w') as f:\n",
    "        json.dump(history, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"✅ {model_name} training completed!\")\n",
    "    return model, history\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 3 if TESTING_MODE else 10  # Fewer epochs for testing\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Train both models\n",
    "models = {}\n",
    "histories = {}\n",
    "\n",
    "# Train model on original data\n",
    "if 'train' in original_dataloaders:\n",
    "    model_original, history_original = train_model(\n",
    "        original_dataloaders, \n",
    "        'unet_original', \n",
    "        epochs=EPOCHS, \n",
    "        learning_rate=LEARNING_RATE\n",
    "    )\n",
    "    models['original'] = model_original\n",
    "    histories['original'] = history_original\n",
    "\n",
    "# Train model on normalized data\n",
    "if 'train' in normalized_dataloaders:\n",
    "    model_normalized, history_normalized = train_model(\n",
    "        normalized_dataloaders, \n",
    "        'unet_normalized', \n",
    "        epochs=EPOCHS, \n",
    "        learning_rate=LEARNING_RATE\n",
    "    )\n",
    "    models['normalized'] = model_normalized\n",
    "    histories['normalized'] = history_normalized\n",
    "\n",
    "print(f\"\\\\n🎉 All models trained successfully!\")\n",
    "logger.info(f\"Model training completed: {len(models)} models trained\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Paired Evaluation and Statistical Analysis\n",
    "\n",
    "Evaluate both models on the same test images and perform statistical comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Performing paired evaluation...\n",
      "   Processed batch 1/7\n",
      "   Processed batch 6/7\n",
      "✅ Paired evaluation completed: 25 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:33:04,222 - INFO - Statistical analysis completed: 6 metrics analyzed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n📊 Statistical Analysis:\n",
      "==================================================\n",
      "\\nDICE:\n",
      "  Original:    0.3569\n",
      "  Normalized:  0.4145\n",
      "  Improvement: +16.14%\n",
      "  Wilcoxon p:  0.021908 *\n",
      "  T-test p:    0.036060 *\n",
      "\\nIOU:\n",
      "  Original:    0.2757\n",
      "  Normalized:  0.3308\n",
      "  Improvement: +19.98%\n",
      "  Wilcoxon p:  0.025505 *\n",
      "  T-test p:    0.067109 \n",
      "\\nPIXEL_ACC:\n",
      "  Original:    0.6059\n",
      "  Normalized:  0.6777\n",
      "  Improvement: +11.85%\n",
      "  Wilcoxon p:  0.005072 **\n",
      "  T-test p:    0.069458 \n",
      "\\nPRECISION:\n",
      "  Original:    0.5216\n",
      "  Normalized:  0.5482\n",
      "  Improvement: +5.10%\n",
      "  Wilcoxon p:  0.012929 *\n",
      "  T-test p:    0.013479 *\n",
      "\\nRECALL:\n",
      "  Original:    0.3479\n",
      "  Normalized:  0.3753\n",
      "  Improvement: +7.88%\n",
      "  Wilcoxon p:  0.691519 \n",
      "  T-test p:    0.401319 \n",
      "\\nF1:\n",
      "  Original:    0.3569\n",
      "  Normalized:  0.4145\n",
      "  Improvement: +16.14%\n",
      "  Wilcoxon p:  0.021908 *\n",
      "  T-test p:    0.036060 *\n",
      "\\n🧪 Hypothesis Testing Summary:\n",
      "========================================\n",
      "✅ DICE: Significant improvement (+16.14%)\n",
      "✅ IOU: Significant improvement (+19.98%)\n",
      "✅ PIXEL_ACC: Significant improvement (+11.85%)\n",
      "✅ PRECISION: Significant improvement (+5.10%)\n",
      "❌ RECALL: No significant difference\n",
      "✅ F1: Significant improvement (+16.14%)\n",
      "\\n🎯 RESEARCH QUESTION 3 RESULTS:\n",
      "===================================\n",
      "🎉 REJECT NULL HYPOTHESIS (H₀)\n",
      "   Stain normalization shows significant improvement in:\n",
      "   - DICE: +16.14%\n",
      "   - IOU: +19.98%\n",
      "   - PIXEL_ACC: +11.85%\n",
      "   - PRECISION: +5.10%\n",
      "   - F1: +16.14%\n",
      "\\n✅ RQ3 Analysis Pipeline Completed!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PAIRED EVALUATION AND STATISTICAL ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_models_paired(models, dataloaders):\n",
    "    \"\"\"Evaluate models on paired data for statistical comparison\"\"\"\n",
    "    \n",
    "    print(\"🔍 Performing paired evaluation...\")\n",
    "    \n",
    "    # Results storage\n",
    "    paired_results = []\n",
    "    \n",
    "    # Get validation dataloaders\n",
    "    original_val = dataloaders['original']['val'] if 'val' in dataloaders['original'] else None\n",
    "    normalized_val = dataloaders['normalized']['val'] if 'val' in dataloaders['normalized'] else None\n",
    "    \n",
    "    if not (original_val and normalized_val):\n",
    "        print(\"⚠️  Validation dataloaders not available for paired evaluation\")\n",
    "        return []\n",
    "    \n",
    "    # Ensure both models are in evaluation mode\n",
    "    models['original'].eval()\n",
    "    models['normalized'].eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get iterators\n",
    "        orig_iter = iter(original_val)\n",
    "        norm_iter = iter(normalized_val)\n",
    "        \n",
    "        batch_count = min(len(original_val), len(normalized_val))\n",
    "        \n",
    "        for batch_idx in range(batch_count):\n",
    "            try:\n",
    "                # Get paired batches\n",
    "                orig_images, orig_masks = next(orig_iter)\n",
    "                norm_images, norm_masks = next(norm_iter)\n",
    "                \n",
    "                # Move to device\n",
    "                orig_images, orig_masks = orig_images.to(device), orig_masks.to(device)\n",
    "                norm_images, norm_masks = norm_images.to(device), norm_masks.to(device)\n",
    "                \n",
    "                # Get predictions\n",
    "                orig_outputs = models['original'](orig_images)\n",
    "                norm_outputs = models['normalized'](norm_images)\n",
    "                \n",
    "                orig_preds = torch.argmax(orig_outputs, dim=1)\n",
    "                norm_preds = torch.argmax(norm_outputs, dim=1)\n",
    "                \n",
    "                # Calculate metrics for each image in batch\n",
    "                batch_size = orig_images.shape[0]\n",
    "                \n",
    "                for i in range(batch_size):\n",
    "                    # Get individual predictions and masks\n",
    "                    orig_pred = orig_preds[i].cpu().numpy()\n",
    "                    norm_pred = norm_preds[i].cpu().numpy()\n",
    "                    orig_mask = orig_masks[i].cpu().numpy()\n",
    "                    norm_mask = norm_masks[i].cpu().numpy()\n",
    "                    \n",
    "                    # Calculate metrics for original model\n",
    "                    orig_metrics = calculate_segmentation_metrics(orig_pred, orig_mask, num_classes=6)\n",
    "                    \n",
    "                    # Calculate metrics for normalized model  \n",
    "                    norm_metrics = calculate_segmentation_metrics(norm_pred, norm_mask, num_classes=6)\n",
    "                    \n",
    "                    # Store paired results\n",
    "                    paired_result = {\n",
    "                        'batch_idx': batch_idx,\n",
    "                        'image_idx': i,\n",
    "                        'original_dice': orig_metrics['avg_dice'],\n",
    "                        'normalized_dice': norm_metrics['avg_dice'],\n",
    "                        'original_iou': orig_metrics['avg_iou'],\n",
    "                        'normalized_iou': norm_metrics['avg_iou'],\n",
    "                        'original_pixel_acc': orig_metrics['pixel_accuracy'],\n",
    "                        'normalized_pixel_acc': norm_metrics['pixel_accuracy'],\n",
    "                        'original_precision': orig_metrics['avg_precision'],\n",
    "                        'normalized_precision': norm_metrics['avg_precision'],\n",
    "                        'original_recall': orig_metrics['avg_recall'],\n",
    "                        'normalized_recall': norm_metrics['avg_recall'],\n",
    "                        'original_f1': orig_metrics['avg_f1'],\n",
    "                        'normalized_f1': norm_metrics['avg_f1']\n",
    "                    }\n",
    "                    \n",
    "                    paired_results.append(paired_result)\n",
    "                \n",
    "                if batch_idx % 5 == 0:\n",
    "                    print(f\"   Processed batch {batch_idx+1}/{batch_count}\")\n",
    "                    \n",
    "            except StopIteration:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error in batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"✅ Paired evaluation completed: {len(paired_results)} image pairs\")\n",
    "    return paired_results\n",
    "\n",
    "# Perform paired evaluation\n",
    "if len(models) == 2:\n",
    "    paired_results = evaluate_models_paired(models, {'original': original_dataloaders, 'normalized': normalized_dataloaders})\n",
    "    \n",
    "    if paired_results:\n",
    "        # Convert to DataFrame for analysis\n",
    "        results_df = pd.DataFrame(paired_results)\n",
    "        \n",
    "        # Save paired results\n",
    "        results_df.to_csv(artifacts_dir / 'results' / 'paired_evaluation_results.csv', index=False)\n",
    "        \n",
    "        # Statistical Analysis\n",
    "        print(\"\\\\n📊 Statistical Analysis:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        metrics_to_test = ['dice', 'iou', 'pixel_acc', 'precision', 'recall', 'f1']\n",
    "        statistical_results = {}\n",
    "        \n",
    "        for metric in metrics_to_test:\n",
    "            original_col = f'original_{metric}'\n",
    "            normalized_col = f'normalized_{metric}'\n",
    "            \n",
    "            if original_col in results_df.columns and normalized_col in results_df.columns:\n",
    "                original_vals = results_df[original_col].dropna()\n",
    "                normalized_vals = results_df[normalized_col].dropna()\n",
    "                \n",
    "                if len(original_vals) > 0 and len(normalized_vals) > 0:\n",
    "                    # Ensure same length for paired tests\n",
    "                    min_len = min(len(original_vals), len(normalized_vals))\n",
    "                    original_vals = original_vals[:min_len]\n",
    "                    normalized_vals = normalized_vals[:min_len]\n",
    "                    \n",
    "                    # Calculate basic statistics\n",
    "                    orig_mean = np.mean(original_vals)\n",
    "                    norm_mean = np.mean(normalized_vals)\n",
    "                    improvement = ((norm_mean - orig_mean) / orig_mean) * 100\n",
    "                    \n",
    "                    # Wilcoxon signed-rank test (non-parametric paired test)\n",
    "                    try:\n",
    "                        wilcoxon_stat, wilcoxon_p = wilcoxon(normalized_vals, original_vals, alternative='two-sided')\n",
    "                    except:\n",
    "                        wilcoxon_stat, wilcoxon_p = np.nan, np.nan\n",
    "                    \n",
    "                    # Paired t-test (parametric paired test)\n",
    "                    try:\n",
    "                        ttest_stat, ttest_p = ttest_rel(normalized_vals, original_vals)\n",
    "                    except:\n",
    "                        ttest_stat, ttest_p = np.nan, np.nan\n",
    "                    \n",
    "                    # Store results\n",
    "                    statistical_results[metric] = {\n",
    "                        'original_mean': orig_mean,\n",
    "                        'normalized_mean': norm_mean,\n",
    "                        'improvement_percent': improvement,\n",
    "                        'wilcoxon_statistic': wilcoxon_stat,\n",
    "                        'wilcoxon_p_value': wilcoxon_p,\n",
    "                        'ttest_statistic': ttest_stat,\n",
    "                        'ttest_p_value': ttest_p,\n",
    "                        'sample_size': min_len,\n",
    "                        'significant_wilcoxon': wilcoxon_p < 0.05 if not np.isnan(wilcoxon_p) else False,\n",
    "                        'significant_ttest': ttest_p < 0.05 if not np.isnan(ttest_p) else False\n",
    "                    }\n",
    "                    \n",
    "                    # Print results\n",
    "                    print(f\"\\\\n{metric.upper()}:\")\n",
    "                    print(f\"  Original:    {orig_mean:.4f}\")\n",
    "                    print(f\"  Normalized:  {norm_mean:.4f}\")\n",
    "                    print(f\"  Improvement: {improvement:+.2f}%\")\n",
    "                    print(f\"  Wilcoxon p:  {wilcoxon_p:.6f} {'***' if wilcoxon_p < 0.001 else '**' if wilcoxon_p < 0.01 else '*' if wilcoxon_p < 0.05 else ''}\")\n",
    "                    print(f\"  T-test p:    {ttest_p:.6f} {'***' if ttest_p < 0.001 else '**' if ttest_p < 0.01 else '*' if ttest_p < 0.05 else ''}\")\n",
    "        \n",
    "        # Save statistical results\n",
    "        stats_df = pd.DataFrame(statistical_results).T\n",
    "        stats_df.to_csv(artifacts_dir / 'results' / 'statistical_analysis.csv')\n",
    "        \n",
    "        with open(artifacts_dir / 'results' / 'statistical_results.json', 'w') as f:\n",
    "            json.dump(statistical_results, f, indent=2, default=str)\n",
    "        \n",
    "        # Summary of hypothesis testing\n",
    "        print(\"\\\\n🧪 Hypothesis Testing Summary:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        significant_metrics = []\n",
    "        for metric, results in statistical_results.items():\n",
    "            if results['significant_wilcoxon'] or results['significant_ttest']:\n",
    "                significant_metrics.append(metric)\n",
    "                improvement = results['improvement_percent']\n",
    "                direction = \"improvement\" if improvement > 0 else \"degradation\"\n",
    "                print(f\"✅ {metric.upper()}: Significant {direction} ({improvement:+.2f}%)\")\n",
    "            else:\n",
    "                print(f\"❌ {metric.upper()}: No significant difference\")\n",
    "        \n",
    "        # Final conclusion\n",
    "        print(f\"\\\\n🎯 RESEARCH QUESTION 3 RESULTS:\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        if significant_metrics:\n",
    "            print(f\"🎉 REJECT NULL HYPOTHESIS (H₀)\")\n",
    "            print(f\"   Stain normalization shows significant improvement in:\")\n",
    "            for metric in significant_metrics:\n",
    "                improvement = statistical_results[metric]['improvement_percent']\n",
    "                print(f\"   - {metric.upper()}: {improvement:+.2f}%\")\n",
    "        else:\n",
    "            print(f\"📊 FAIL TO REJECT NULL HYPOTHESIS (H₀)\")\n",
    "            print(f\"   No significant improvement found with stain normalization\")\n",
    "        \n",
    "        logger.info(f\"Statistical analysis completed: {len(statistical_results)} metrics analyzed\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️  Both models not available for paired evaluation\")\n",
    "    \n",
    "print(\"\\\\n✅ RQ3 Analysis Pipeline Completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary and Artifacts\n",
    "\n",
    "### Complete RQ3 Pipeline Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 RQ3 Complete Pipeline Summary\n",
      "==================================================\n",
      "🎯 Pipeline Status: ✅ COMPLETED\n",
      "🧪 Mode: TESTING\n",
      "🔬 Tissues: 5 (Breast, Colon, Adrenal_gland, Esophagus, Bile-duct)\n",
      "📊 Images: 75\n",
      "🤖 Models: 2 trained\n",
      "📈 Statistics: ✅ Completed\n",
      "⚡ GPU: ✅ Used\n",
      "\n",
      "📁 Generated Artifacts:\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 17:33:24,775 - INFO - RQ3 complete pipeline execution finished successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 datasets    : 402 files - Processed image datasets (original & normalized)\n",
      "📂 checkpoints :   4 files - Trained model weights\n",
      "📂 results     :  11 files - Analysis results and statistics\n",
      "📂 plots       :   0 files - Visualizations and plots\n",
      "📂 logs        :   1 files - Execution logs\n",
      "\n",
      "📋 Key Result Files:\n",
      "   ✅ tissue_selection.json\n",
      "   ✅ sample_config.json\n",
      "   ✅ target_metadata.json\n",
      "   ✅ normalization_results.json\n",
      "   ✅ processing_stats.json\n",
      "   ✅ paired_evaluation_results.csv\n",
      "   ✅ statistical_analysis.csv\n",
      "   ✅ statistical_results.json\n",
      "\n",
      "🎯 Research Question 3 Conclusion:\n",
      "========================================\n",
      "🎉 CONCLUSION: REJECT NULL HYPOTHESIS (H₀)\n",
      "   📊 5/6 metrics show significant improvement\n",
      "   📈 Stain normalization DOES improve U-Net segmentation performance\n",
      "   🏆 Top improvements:\n",
      "      - IOU: +19.98%\n",
      "      - F1: +16.14%\n",
      "      - DICE: +16.14%\n",
      "\n",
      "⚡ Performance Summary:\n",
      "=========================\n",
      "📊 Images processed: 75\n",
      "⏱️  Processing time: 15.79s\n",
      "🚀 Processing speed: 4.8 images/sec\n",
      "📈 Full dataset estimate: 17.8 minutes\n",
      "\n",
      "🎉 RQ3 GPU-Accelerated Pipeline Complete!\n",
      "📁 All artifacts saved to: /workspace/HistoPathologyResearch/artifacts/rq3\n",
      "🔬 Ready for publication and further analysis\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY AND ARTIFACT DOCUMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"📋 RQ3 Complete Pipeline Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Pipeline execution summary\n",
    "execution_summary = {\n",
    "    'pipeline_completed': True,\n",
    "    'testing_mode': TESTING_MODE,\n",
    "    'total_tissues': len(selected_tissues),\n",
    "    'selected_tissues': selected_tissues,\n",
    "    'total_sample_images': total_sample_images if 'total_sample_images' in locals() else 0,\n",
    "    'models_trained': len(models) if 'models' in locals() else 0,\n",
    "    'statistical_analysis_completed': 'statistical_results' in locals(),\n",
    "    'gpu_acceleration_used': device.type == 'cuda',\n",
    "    'execution_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "print(f\"🎯 Pipeline Status: {'✅ COMPLETED' if execution_summary['pipeline_completed'] else '❌ INCOMPLETE'}\")\n",
    "print(f\"🧪 Mode: {'TESTING' if execution_summary['testing_mode'] else 'PRODUCTION'}\")\n",
    "print(f\"🔬 Tissues: {execution_summary['total_tissues']} ({', '.join(execution_summary['selected_tissues'])})\")\n",
    "print(f\"📊 Images: {execution_summary['total_sample_images']:,}\")\n",
    "print(f\"🤖 Models: {execution_summary['models_trained']} trained\")\n",
    "print(f\"📈 Statistics: {'✅ Completed' if execution_summary['statistical_analysis_completed'] else '❌ Pending'}\")\n",
    "print(f\"⚡ GPU: {'✅ Used' if execution_summary['gpu_acceleration_used'] else '❌ CPU only'}\")\n",
    "\n",
    "# Document all artifacts\n",
    "print(f\"\\n📁 Generated Artifacts:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "artifact_categories = {\n",
    "    'datasets': 'Processed image datasets (original & normalized)',\n",
    "    'checkpoints': 'Trained model weights',\n",
    "    'results': 'Analysis results and statistics', \n",
    "    'plots': 'Visualizations and plots',\n",
    "    'logs': 'Execution logs'\n",
    "}\n",
    "\n",
    "for category, description in artifact_categories.items():\n",
    "    category_path = artifacts_dir / category\n",
    "    if category_path.exists():\n",
    "        file_count = len(list(category_path.rglob('*')))\n",
    "        print(f\"📂 {category:12}: {file_count:3} files - {description}\")\n",
    "\n",
    "# Key result files\n",
    "key_files = [\n",
    "    'tissue_selection.json',\n",
    "    'sample_config.json', \n",
    "    'target_metadata.json',\n",
    "    'normalization_results.json',\n",
    "    'processing_stats.json',\n",
    "    'paired_evaluation_results.csv',\n",
    "    'statistical_analysis.csv',\n",
    "    'statistical_results.json'\n",
    "]\n",
    "\n",
    "print(f\"\\n📋 Key Result Files:\")\n",
    "for filename in key_files:\n",
    "    filepath = artifacts_dir / 'results' / filename\n",
    "    status = '✅' if filepath.exists() else '❌'\n",
    "    print(f\"   {status} {filename}\")\n",
    "\n",
    "# Research question conclusion\n",
    "print(f\"\\n🎯 Research Question 3 Conclusion:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if 'statistical_results' in locals() and statistical_results:\n",
    "    # Count significant improvements\n",
    "    significant_count = sum(1 for metric, results in statistical_results.items() \n",
    "                          if results.get('significant_wilcoxon', False) or results.get('significant_ttest', False))\n",
    "    \n",
    "    total_metrics = len(statistical_results)\n",
    "    \n",
    "    if significant_count > 0:\n",
    "        print(\"🎉 CONCLUSION: REJECT NULL HYPOTHESIS (H₀)\")\n",
    "        print(f\"   📊 {significant_count}/{total_metrics} metrics show significant improvement\")\n",
    "        print(\"   📈 Stain normalization DOES improve U-Net segmentation performance\")\n",
    "        \n",
    "        # Show top improvements\n",
    "        improvements = [(metric, results['improvement_percent']) \n",
    "                       for metric, results in statistical_results.items()\n",
    "                       if results.get('significant_wilcoxon', False) or results.get('significant_ttest', False)]\n",
    "        \n",
    "        if improvements:\n",
    "            improvements.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "            print(\"   🏆 Top improvements:\")\n",
    "            for metric, improvement in improvements[:3]:\n",
    "                print(f\"      - {metric.upper()}: {improvement:+.2f}%\")\n",
    "    else:\n",
    "        print(\"📊 CONCLUSION: FAIL TO REJECT NULL HYPOTHESIS (H₀)\")\n",
    "        print(\"   ❌ No significant improvement found with stain normalization\")\n",
    "        print(\"   📉 Current evidence does not support H₁\")\n",
    "else:\n",
    "    print(\"⚠️  Statistical analysis not completed - cannot draw conclusion\")\n",
    "\n",
    "# Save execution summary\n",
    "with open(artifacts_dir / 'results' / 'execution_summary.json', 'w') as f:\n",
    "    json.dump(execution_summary, f, indent=2, default=str)\n",
    "\n",
    "# Performance summary\n",
    "if 'processing_stats' in locals():\n",
    "    print(f\"\\n⚡ Performance Summary:\")\n",
    "    print(\"=\" * 25)\n",
    "    total_time = processing_stats.get('processing_time', 0)\n",
    "    total_processed = processing_stats.get('total_processed', 0)\n",
    "    \n",
    "    print(f\"📊 Images processed: {total_processed:,}\")\n",
    "    print(f\"⏱️  Processing time: {total_time:.2f}s\")\n",
    "    print(f\"🚀 Processing speed: {total_processed/total_time:.1f} images/sec\" if total_time > 0 else \"🚀 Processing speed: N/A\")\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        estimated_full_time = (5072 * total_time / total_processed) / 60 if total_processed > 0 else 0\n",
    "        print(f\"📈 Full dataset estimate: {estimated_full_time:.1f} minutes\")\n",
    "\n",
    "print(f\"\\n🎉 RQ3 GPU-Accelerated Pipeline Complete!\")\n",
    "print(f\"📁 All artifacts saved to: {artifacts_dir}\")\n",
    "print(f\"🔬 Ready for publication and further analysis\")\n",
    "\n",
    "logger.info(\"RQ3 complete pipeline execution finished successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
