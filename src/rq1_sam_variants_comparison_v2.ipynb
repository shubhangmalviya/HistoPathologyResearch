{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "✅ Dependencies installation cell executed.\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "%pip install -q --upgrade pip\n",
    "%pip install -q statsmodels scikit-image seaborn matplotlib pandas scipy opencv-python-headless\n",
    "\n",
    "# Segment Anything\n",
    "try:\n",
    "    import segment_anything  # noqa: F401\n",
    "except Exception:\n",
    "    %pip install -q git+https://github.com/facebookresearch/segment-anything.git\n",
    "\n",
    "print(\"✅ Dependencies installation cell executed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels OK\n",
      "skimage OK\n",
      "seaborn OK\n",
      "matplotlib OK\n",
      "pandas OK\n",
      "scipy OK\n",
      "PIL OK\n",
      "cv2 OK\n",
      "segment_anything OK\n",
      "tiatoolbox OK\n",
      "torchvision OK\n",
      "torch OK, CUDA: True\n",
      "✅ Dependency check complete.\n"
     ]
    }
   ],
   "source": [
    "# Dependency installation / verification (runs in Python, no magics)\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def _pip_install(args):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *args])\n",
    "\n",
    "def ensure_pkg(module_name: str, pip_spec: str | None = None) -> None:\n",
    "    try:\n",
    "        importlib.import_module(module_name)\n",
    "        print(f\"{module_name} OK\")\n",
    "        return\n",
    "    except Exception:\n",
    "        pass\n",
    "    spec = pip_spec or module_name\n",
    "    print(f\"Installing {spec} ...\")\n",
    "    try:\n",
    "        _pip_install([spec])\n",
    "    except subprocess.CalledProcessError:\n",
    "        # retry with --user to avoid touching system packages\n",
    "        try:\n",
    "            print(f\"Retrying {spec} with --user ...\")\n",
    "            _pip_install([\"--user\", spec])\n",
    "        except subprocess.CalledProcessError:\n",
    "            # special-case tiatoolbox to avoid distutils uninstall issues (e.g., blinker)\n",
    "            if module_name == \"tiatoolbox\":\n",
    "                try:\n",
    "                    print(\"Retrying tiatoolbox with --user and --ignore-installed blinker ...\")\n",
    "                    _pip_install([\"--user\", \"tiatoolbox\", \"--ignore-installed\", \"blinker\"]) \n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    raise e\n",
    "            else:\n",
    "                raise\n",
    "    importlib.import_module(module_name)\n",
    "    print(f\"{module_name} OK\")\n",
    "\n",
    "# Core scientific & plotting\n",
    "for mod, spec in [\n",
    "    (\"statsmodels\", \"statsmodels\"),\n",
    "    (\"skimage\", \"scikit-image\"),\n",
    "    (\"seaborn\", \"seaborn\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"scipy\", \"scipy\"),\n",
    "    (\"PIL\", \"Pillow\"),\n",
    "    (\"cv2\", \"opencv-python-headless\"),\n",
    "]:\n",
    "    ensure_pkg(mod, spec)\n",
    "\n",
    "# Segment Anything\n",
    "try:\n",
    "    importlib.import_module(\"segment_anything\")\n",
    "    print(\"segment_anything OK\")\n",
    "except Exception:\n",
    "    print(\"Installing Segment Anything from GitHub ...\")\n",
    "    _pip_install([\"git+https://github.com/facebookresearch/segment-anything.git\"])\n",
    "    importlib.import_module(\"segment_anything\")\n",
    "    print(\"segment_anything OK\")\n",
    "\n",
    "# TIAToolbox (official HoVer-Net)\n",
    "try:\n",
    "    ensure_pkg(\"tiatoolbox\", \"tiatoolbox\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"❗ tiatoolbox installation failed. Consider using a virtual environment and re-running this cell:\\n  python -m venv .venv && source .venv/bin/activate && python -m pip install -U pip && pip install tiatoolbox\")\n",
    "    raise\n",
    "\n",
    "# TorchVision (fallback HoverNet uses it; attempt install if missing)\n",
    "try:\n",
    "    importlib.import_module(\"torchvision\")\n",
    "    print(\"torchvision OK\")\n",
    "except Exception:\n",
    "    try:\n",
    "        print(\"Installing torchvision ... (ensure it matches your torch version)\")\n",
    "        _pip_install([\"torchvision\"])\n",
    "        importlib.import_module(\"torchvision\")\n",
    "        print(\"torchvision OK\")\n",
    "    except Exception:\n",
    "        print(\"Warning: torchvision install failed; if using TIAToolbox HoVer-Net this is optional.\")\n",
    "\n",
    "# Torch presence + CUDA check\n",
    "try:\n",
    "    import torch  # noqa: F401\n",
    "    import torch as _torch\n",
    "    print(\"torch OK, CUDA:\", _torch.cuda.is_available())\n",
    "except Exception:\n",
    "    print(\"Warning: torch not available. Install a platform-appropriate torch manually if needed.\")\n",
    "\n",
    "print(\"✅ Dependency check complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1: SAM Variants vs Established Models on PanNuke\n",
    "\n",
    "**Research Question**: Do different variants of the Segment Anything Model (SAM), including domain-adapted PathoSAM, achieve competitive or superior nuclei instance segmentation performance on PanNuke compared to established models (HoVer-Net, CellViT, LKCell) and a U-Net baseline?\n",
    "\n",
    "- **H0 (Null)**: SAM variants do not significantly outperform established models in mPQ or detection F1.\n",
    "- **H1 (Alt.)**: At least one SAM variant significantly outperforms baselines in mPQ or detection F1.\n",
    "\n",
    "### What this notebook does\n",
    "- Loads PanNuke tiles via a reusable dataset\n",
    "- Runs inference for available models:\n",
    "  - SAM variants (if checkpoints available)\n",
    "  - U-Net baseline (checkpoint-gated)\n",
    "- Converts predictions to instance masks and computes: PQ, object F1, AJI, Dice\n",
    "- Performs paired statistics with multiple-comparison correction\n",
    "- Saves CSVs, figures, and an HTML report under `reports/rq1`\n",
    "\n",
    "Note: HoVer-Net, CellViT, and LKCell slots are scaffolded for future integration; this notebook focuses on SAM variants and a U-Net baseline to establish a robust, reproducible evaluation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project-local imports\n",
    "import sys\n",
    "if \"__file__\" in globals():\n",
    "    SRC_DIR = Path(__file__).resolve().parent\n",
    "else:\n",
    "    SRC_DIR = Path.cwd()\n",
    "sys.path.append(str(SRC_DIR))\n",
    "from datasets.pannuke_tissue_dataset import PanNukeTissueDataset\n",
    "from models.unet import UNet\n",
    "\n",
    "# Metrics (instance-aware)\n",
    "from metrics.seg_metrics import (\n",
    "    reconstruct_instances,\n",
    "    dice_coefficient,\n",
    "    aji_aggregated_jaccard,\n",
    "    pq_panoptic,\n",
    "    f1_object,\n",
    ")\n",
    "\n",
    "# Reproducibility & device\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = SRC_DIR.parent\n",
    "DATASET_TISSUES = PROJECT_ROOT / \"dataset_tissues\"\n",
    "REPORTS_DIR = PROJECT_ROOT / \"reports\" / \"rq1\"\n",
    "FIG_DIR = REPORTS_DIR / \"figures\"\n",
    "CSV_DIR = REPORTS_DIR / \"tables\"\n",
    "for d in [REPORTS_DIR, FIG_DIR, CSV_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tissues: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tissue</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adrenal_gland</th>\n",
       "      <td>88</td>\n",
       "      <td>314</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bile-duct</th>\n",
       "      <td>84</td>\n",
       "      <td>302</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breast</th>\n",
       "      <td>471</td>\n",
       "      <td>1692</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colon</th>\n",
       "      <td>288</td>\n",
       "      <td>1036</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Esophagus</th>\n",
       "      <td>85</td>\n",
       "      <td>305</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split          test  train  val\n",
       "tissue                         \n",
       "Adrenal_gland    88    314   35\n",
       "Bile-duct        84    302   34\n",
       "Breast          471   1692  188\n",
       "Colon           288   1036  116\n",
       "Esophagus        85    305   34"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset setup\n",
    "available_tissues = [p.name for p in DATASET_TISSUES.iterdir() if p.is_dir()]\n",
    "print(\"Tissues:\", len(available_tissues))\n",
    "\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 6\n",
    "\n",
    "# Simple transforms via dataset defaults; they already resize/normalize if needed\n",
    "\n",
    "def make_loader(tissue: str, split: str = \"test\") -> DataLoader:\n",
    "    ds = PanNukeTissueDataset(\n",
    "        str(DATASET_TISSUES / tissue),\n",
    "        split=split,\n",
    "        image_transform=None,\n",
    "        target_transform=None,\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Small EDA count table\n",
    "records = []\n",
    "for t in sorted(available_tissues):\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        try:\n",
    "            ds = PanNukeTissueDataset(str(DATASET_TISSUES / t), split=split)\n",
    "            records.append({\"tissue\": t, \"split\": split, \"n\": len(ds)})\n",
    "        except Exception:\n",
    "            pass\n",
    "eda_df = pd.DataFrame(records).pivot(index=\"tissue\", columns=\"split\", values=\"n\").fillna(0).astype(int)\n",
    "eda_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net baseline loader (checkpoint optional)\n",
    "\n",
    "def load_unet_checkpoint(ckpt_path: Path, num_classes: int = 7) -> nn.Module:\n",
    "    model = UNet(in_channels=3, num_classes=num_classes)\n",
    "    if ckpt_path.exists():\n",
    "        state = torch.load(ckpt_path, map_location=device)\n",
    "        # allow raw state or dict\n",
    "        state_dict = state.get('model_state', state)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        print(f\"Loaded U-Net weights from {ckpt_path}\")\n",
    "    else:\n",
    "        print(f\"U-Net checkpoint not found at {ckpt_path}; using randomly initialized model\")\n",
    "    model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "# SAM wrapper (automatic mask generation -> instance map)\n",
    "try:\n",
    "    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "    SAM_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(\"SAM not available:\", e)\n",
    "    SAM_AVAILABLE = False\n",
    "\n",
    "class SAMWrapper:\n",
    "    def __init__(self, model_type: str, checkpoint: str | None = None):\n",
    "        assert SAM_AVAILABLE, \"segment_anything not installed\"\n",
    "        if checkpoint and os.path.isfile(checkpoint):\n",
    "            self.sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
    "        else:\n",
    "            self.sam = sam_model_registry[model_type]()\n",
    "        # move model to selected device for GPU/MPS acceleration\n",
    "        self.sam.to(device)\n",
    "        self.predictor = SamPredictor(self.sam)\n",
    "        # Use single-crop to avoid torchvision box_area 1D bug; adjust for stability and speed\n",
    "        self.mask_gen = SamAutomaticMaskGenerator(\n",
    "            model=self.sam,\n",
    "            points_per_side=8,\n",
    "            pred_iou_thresh=0.7,\n",
    "            stability_score_thresh=0.92,\n",
    "            crop_n_layers=0,  # single crop to avoid multi-crop NMS path\n",
    "            crop_n_points_downscale_factor=2,\n",
    "            min_mask_region_area=80,\n",
    "        )\n",
    "\n",
    "    def _masks_to_instances(self, masks: List[Dict], min_area: int = 50) -> np.ndarray:\n",
    "        \"\"\"Convert SAM masks (list of dicts) to instance map.\"\"\"\n",
    "        if not masks:\n",
    "            return np.zeros((256, 256), dtype=np.int32)\n",
    "        \n",
    "        # Get image dimensions from first mask\n",
    "        first_seg = masks[0]['segmentation']\n",
    "        H, W = first_seg.shape\n",
    "        inst = np.zeros((H, W), dtype=np.int32)\n",
    "        \n",
    "        # Sort masks by area (largest first) for better instance assignment\n",
    "        masks_sorted = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
    "        \n",
    "        instance_id = 1\n",
    "        for mask_dict in masks_sorted:\n",
    "            seg = mask_dict['segmentation']\n",
    "            area = mask_dict['area']\n",
    "            \n",
    "            # Skip small masks\n",
    "            if area < min_area:\n",
    "                continue\n",
    "                \n",
    "            # Convert to boolean mask\n",
    "            mask = seg.astype(bool)\n",
    "            \n",
    "            # Only assign to pixels not already assigned to an instance\n",
    "            available_pixels = (inst == 0) & mask\n",
    "            if available_pixels.sum() > min_area // 2:  # At least half the min area available\n",
    "                inst[available_pixels] = instance_id\n",
    "                instance_id += 1\n",
    "        \n",
    "        return inst\n",
    "\n",
    "    def _predict_instances_fallback(self, image_np: np.ndarray) -> np.ndarray:\n",
    "        # Grid prompt fallback using SamPredictor\n",
    "        self.predictor.set_image(image_np)\n",
    "        H, W = image_np.shape[:2]\n",
    "        grid = 6  # Reduced for speed\n",
    "        ys = np.linspace(H//4, 3*H//4, grid, dtype=np.int32)\n",
    "        xs = np.linspace(W//4, 3*W//4, grid, dtype=np.int32)\n",
    "        pts = np.stack(np.meshgrid(xs, ys), axis=-1).reshape(-1, 2)\n",
    "        \n",
    "        fake_masks = []  # Create fake mask dicts similar to SAM format\n",
    "        batch = 32\n",
    "        for i in range(0, len(pts), batch):\n",
    "            coords = pts[i:i+batch]\n",
    "            labels = np.ones((coords.shape[0],), dtype=np.int32)\n",
    "            try:\n",
    "                m, _, _ = self.predictor.predict(point_coords=coords, point_labels=labels, multimask_output=False)\n",
    "                # m shape: (N, H, W)\n",
    "                for j in range(m.shape[0]):\n",
    "                    mask = m[j] > 0\n",
    "                    if mask.sum() > 50:  # Only keep reasonable sized masks\n",
    "                        fake_masks.append({\n",
    "                            'segmentation': mask,\n",
    "                            'area': int(mask.sum())\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Fallback prediction error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not fake_masks:\n",
    "            return np.zeros((H, W), dtype=np.int32)\n",
    "        return self._masks_to_instances(fake_masks)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_instances(self, image_np: np.ndarray) -> np.ndarray:\n",
    "        # image_np: HxWx3 uint8\n",
    "        try:\n",
    "            masks = self.mask_gen.generate(image_np)\n",
    "            if masks:\n",
    "                # masks is a list of dicts with 'segmentation', 'area', etc.\n",
    "                return self._masks_to_instances(masks)\n",
    "            # no masks -> fallback\n",
    "            return self._predict_instances_fallback(image_np)\n",
    "        except Exception as e:\n",
    "            print(f\"SAM generation failed: {e}\")\n",
    "            # Fallback using point grid prompts\n",
    "            return self._predict_instances_fallback(image_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference helpers\n",
    "from PIL import Image\n",
    "\n",
    "@torch.no_grad()\n",
    "def unet_predict_instances(model: nn.Module, img_tensor: torch.Tensor) -> np.ndarray:\n",
    "    # img_tensor: 3xHxW (normalized)\n",
    "    model.eval()\n",
    "    logits = model(img_tensor.unsqueeze(0).to(device))\n",
    "    sem = torch.argmax(logits, dim=1).squeeze(0).detach().cpu().numpy().astype(np.uint8)\n",
    "    # derive boundary from semantic changes (FIXED)\n",
    "    from scipy import ndimage\n",
    "    foreground = (sem > 0).astype(np.uint8)\n",
    "    eroded = ndimage.binary_erosion(foreground).astype(np.uint8)\n",
    "    boundary = (foreground - eroded).astype(np.uint8)\n",
    "    inst = reconstruct_instances(sem, boundary)\n",
    "    return inst\n",
    "\n",
    "\n",
    "def tensor_to_uint8(rgb_tensor: torch.Tensor) -> np.ndarray:\n",
    "    # approximate inverse of default normalization for visualization/SAM\n",
    "    arr = rgb_tensor.permute(1,2,0).cpu().numpy()\n",
    "    arr = arr * np.array([0.229, 0.224, 0.225])[None,None,:] + np.array([0.485, 0.456, 0.406])[None,None,:]\n",
    "    arr = np.clip(arr, 0, 1)\n",
    "    return (arr * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def evaluate_on_tissue(tissue: str, models: Dict[str, object], n_limit: int | None = None) -> List[Dict]:\n",
    "    loader = make_loader(tissue, split=\"test\")\n",
    "    results = []\n",
    "    seen = 0\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        images, targets = batch  # targets are semantic gt\n",
    "        for b in range(images.shape[0]):\n",
    "            if n_limit is not None and seen >= n_limit:\n",
    "                return results\n",
    "            img_t = images[b]\n",
    "            gt_sem = targets[b].numpy()\n",
    "            # GT instance reconstruction from sem + boundary (FIXED)\n",
    "            from scipy import ndimage\n",
    "            foreground = (gt_sem > 0).astype(np.uint8)\n",
    "            eroded = ndimage.binary_erosion(foreground).astype(np.uint8)\n",
    "            gt_boundary = (foreground - eroded).astype(np.uint8)\n",
    "            gt_inst = reconstruct_instances(gt_sem, gt_boundary)\n",
    "            \n",
    "            # Debug first image\n",
    "            if batch_idx == 0 and b == 0:\n",
    "                print(f\"\\n=== DEBUG FIRST IMAGE ===\")\n",
    "                print(f\"GT semantic shape: {gt_sem.shape}, unique: {np.unique(gt_sem)}\")\n",
    "                print(f\"GT boundary sum: {gt_boundary.sum()}\")\n",
    "                print(f\"GT instances shape: {gt_inst.shape}, unique instances: {len(np.unique(gt_inst))-1}\")\n",
    "            \n",
    "            # Per-image id for pairing\n",
    "            image_id = f\"{tissue}/test/{batch_idx:05d}_{b}\"\n",
    "            # Evaluate each model (generic: if wrapper exposes predict_instances, use it)\n",
    "            for name, model in models.items():\n",
    "                if hasattr(model, 'predict_instances'):\n",
    "                    img_u8 = tensor_to_uint8(img_t)\n",
    "                    pred_inst = model.predict_instances(img_u8)\n",
    "                else:\n",
    "                    pred_inst = unet_predict_instances(model, img_t)\n",
    "                \n",
    "                # Debug first prediction\n",
    "                if batch_idx == 0 and b == 0:\n",
    "                    print(f\"{name} pred shape: {pred_inst.shape}, unique instances: {len(np.unique(pred_inst))-1}\")\n",
    "                    print(f\"{name} pred max: {pred_inst.max()}, nonzero pixels: {(pred_inst > 0).sum()}\")\n",
    "                \n",
    "                # Metrics\n",
    "                pq = pq_panoptic(gt_inst, pred_inst)\n",
    "                f1o = f1_object(gt_inst, pred_inst)\n",
    "                aji = aji_aggregated_jaccard(gt_inst, pred_inst)\n",
    "                dice = dice_coefficient(gt_sem, (pred_inst > 0).astype(np.uint8), num_classes=2, ignore_background=False)\n",
    "                \n",
    "                # Debug first metrics\n",
    "                if batch_idx == 0 and b == 0:\n",
    "                    print(f\"{name} metrics: PQ={pq:.3f}, F1={f1o:.3f}, AJI={aji:.3f}, Dice={dice:.3f}\")\n",
    "                \n",
    "                results.append({\n",
    "                    \"tissue\": tissue,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"model\": name,\n",
    "                    \"pq\": pq,\n",
    "                    \"f1_object\": f1o,\n",
    "                    \"aji\": aji,\n",
    "                    \"dice_bin\": dice,\n",
    "                })\n",
    "            seen += 1\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2025-09-07|10:27:24.001| [WARNING] /tmp/ipykernel_9854/2727521621.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(ckpt_path, map_location=device)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded U-Net weights from /workspace/HistoPathologyResearch/artifacts/rq3_enhanced/checkpoints/unet_original_enhanced_best.pth\n",
      "Models configured: ['unet_baseline', 'sam_vit_b', 'sam_vit_l', 'sam_vit_h']\n"
     ]
    }
   ],
   "source": [
    "# Configure models (gate by availability)\n",
    "MODELS: Dict[str, object] = {}\n",
    "\n",
    "# U-Net baseline checkpoint (update if you have a trained model)\n",
    "UNET_CKPT = PROJECT_ROOT / \"artifacts\" / \"rq3_enhanced\" / \"checkpoints\" / \"unet_original_enhanced_best.pth\"\n",
    "MODELS[\"unet_baseline\"] = load_unet_checkpoint(UNET_CKPT, num_classes=7)\n",
    "\n",
    "# SAM variants (require segment_anything + optional checkpoints)\n",
    "if SAM_AVAILABLE:\n",
    "    try:\n",
    "        MODELS[\"sam_vit_b\"] = SAMWrapper(\"vit_b\")\n",
    "    except Exception as e:\n",
    "        print(\"Skipping sam_vit_b:\", e)\n",
    "    try:\n",
    "        MODELS[\"sam_vit_l\"] = SAMWrapper(\"vit_l\")\n",
    "    except Exception as e:\n",
    "        print(\"Skipping sam_vit_l:\", e)\n",
    "    try:\n",
    "        MODELS[\"sam_vit_h\"] = SAMWrapper(\"vit_h\")\n",
    "    except Exception as e:\n",
    "        print(\"Skipping sam_vit_h:\", e)\n",
    "\n",
    "print(\"Models configured:\", list(MODELS.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIAToolbox HoVer-Net integration removed as requested\n",
    "TIA_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models configured: ['unet_baseline', 'sam_vit_b', 'sam_vit_l', 'sam_vit_h']\n"
     ]
    }
   ],
   "source": [
    "# HoVer-Net (placeholder) removed as requested\n",
    "print('Models configured:', list(MODELS.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Test single image evaluation\n",
    "print(\"=== DEBUGGING SINGLE IMAGE ===\")\n",
    "tissue = \"Adrenal_gland\"\n",
    "debug_rows = evaluate_on_tissue(tissue, MODELS, n_limit=1)\n",
    "print(f\"Debug results: {len(debug_rows)} rows\")\n",
    "for row in debug_rows:\n",
    "    print(f\"  {row['model']}: PQ={row['pq']:.3f}, F1={row['f1_object']:.3f}, AJI={row['aji']:.3f}\")\n",
    "print(\"=== END DEBUG ===\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Adrenal_gland (remaining images: 100) ...\n",
      "Evaluating Bile-duct (remaining images: 12) ...\n",
      "Processed images: 100\n",
      "          tissue                    image_id          model   pq  f1_object  \\\n",
      "0  Adrenal_gland  Adrenal_gland/test/00000_0  unet_baseline  0.0        0.0   \n",
      "1  Adrenal_gland  Adrenal_gland/test/00000_0      sam_vit_b  0.0        0.0   \n",
      "2  Adrenal_gland  Adrenal_gland/test/00000_0      sam_vit_l  0.0        0.0   \n",
      "3  Adrenal_gland  Adrenal_gland/test/00000_0      sam_vit_h  0.0        0.0   \n",
      "4  Adrenal_gland  Adrenal_gland/test/00000_1  unet_baseline  0.0        0.0   \n",
      "\n",
      "        aji  dice_bin  \n",
      "0  0.000000  0.427778  \n",
      "1  0.004918  0.386383  \n",
      "2  0.005273  0.301359  \n",
      "3  0.005777  0.332589  \n",
      "4  0.000000  0.451921  \n",
      "Saved: /workspace/HistoPathologyResearch/reports/rq1/tables/per_image_instance_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation across tissues (global cap of 100 images)\n",
    "GLOBAL_LIMIT = 100\n",
    "ALL_ROWS: List[Dict] = []\n",
    "processed_images = 0\n",
    "\n",
    "for tissue in sorted(available_tissues):\n",
    "    remaining = GLOBAL_LIMIT - processed_images\n",
    "    if remaining <= 0:\n",
    "        break\n",
    "    print(f\"Evaluating {tissue} (remaining images: {remaining}) ...\")\n",
    "    rows = evaluate_on_tissue(tissue, MODELS, n_limit=remaining)\n",
    "    ALL_ROWS.extend(rows)\n",
    "    if rows:\n",
    "        new_imgs = len({r[\"image_id\"] for r in rows})\n",
    "        processed_images += new_imgs\n",
    "\n",
    "print(f\"Processed images: {processed_images}\")\n",
    "res_df = pd.DataFrame(ALL_ROWS)\n",
    "print(res_df.head())\n",
    "\n",
    "# Save per-image table\n",
    "csv_path = CSV_DIR / \"per_image_instance_metrics.csv\"\n",
    "res_df.to_csv(csv_path, index=False)\n",
    "print(\"Saved:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">pq</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f1_object</th>\n",
       "      <th colspan=\"3\" halign=\"left\">aji</th>\n",
       "      <th colspan=\"3\" halign=\"left\">dice_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sam_vit_b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4122</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sam_vit_h</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sam_vit_l</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unet_baseline</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pq            f1_object                aji                \\\n",
       "              mean  std count      mean  std count    mean     std count   \n",
       "model                                                                      \n",
       "sam_vit_b      0.0  0.0   100       0.0  0.0   100  0.0056  0.0045   100   \n",
       "sam_vit_h      0.0  0.0   100       0.0  0.0   100  0.0059  0.0047   100   \n",
       "sam_vit_l      0.0  0.0   100       0.0  0.0   100  0.0050  0.0042   100   \n",
       "unet_baseline  0.0  0.0   100       0.0  0.0   100  0.0000  0.0000   100   \n",
       "\n",
       "              dice_bin                \n",
       "                  mean     std count  \n",
       "model                                 \n",
       "sam_vit_b       0.4122  0.0175   100  \n",
       "sam_vit_h       0.3210  0.0262   100  \n",
       "sam_vit_l       0.3344  0.0383   100  \n",
       "unet_baseline   0.7913  0.2226   100  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_cols = [\"pq\", \"f1_object\", \"aji\", \"dice_bin\"]\n",
    "summary = res_df.groupby(\"model\")[metrics_cols].agg([\"mean\", \"std\", \"count\"]).round(4)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspace/HistoPathologyResearch/reports/rq1/tables/pairwise_stats_bh.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>t_p</th>\n",
       "      <th>w_p</th>\n",
       "      <th>t_p_bh</th>\n",
       "      <th>t_p_sig_bh</th>\n",
       "      <th>w_p_bh</th>\n",
       "      <th>w_p_sig_bh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unet_baseline</td>\n",
       "      <td>sam_vit_b</td>\n",
       "      <td>aji</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.005650</td>\n",
       "      <td>3.887519e-22</td>\n",
       "      <td>3.896560e-18</td>\n",
       "      <td>1.166256e-21</td>\n",
       "      <td>True</td>\n",
       "      <td>7.793120e-18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unet_baseline</td>\n",
       "      <td>sam_vit_l</td>\n",
       "      <td>aji</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.005019</td>\n",
       "      <td>6.536200e-21</td>\n",
       "      <td>3.896560e-18</td>\n",
       "      <td>1.307240e-20</td>\n",
       "      <td>True</td>\n",
       "      <td>7.793120e-18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unet_baseline</td>\n",
       "      <td>sam_vit_h</td>\n",
       "      <td>aji</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.005943</td>\n",
       "      <td>1.986319e-22</td>\n",
       "      <td>3.896560e-18</td>\n",
       "      <td>1.166256e-21</td>\n",
       "      <td>True</td>\n",
       "      <td>7.793120e-18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sam_vit_b</td>\n",
       "      <td>sam_vit_l</td>\n",
       "      <td>aji</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>8.512050e-06</td>\n",
       "      <td>7.459505e-06</td>\n",
       "      <td>1.021446e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>8.951406e-06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sam_vit_b</td>\n",
       "      <td>sam_vit_h</td>\n",
       "      <td>aji</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>2.345791e-03</td>\n",
       "      <td>1.037475e-03</td>\n",
       "      <td>2.345791e-03</td>\n",
       "      <td>True</td>\n",
       "      <td>1.037475e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model1     model2 metric    n  mean_diff           t_p  \\\n",
       "0  unet_baseline  sam_vit_b    aji  100  -0.005650  3.887519e-22   \n",
       "1  unet_baseline  sam_vit_l    aji  100  -0.005019  6.536200e-21   \n",
       "2  unet_baseline  sam_vit_h    aji  100  -0.005943  1.986319e-22   \n",
       "3      sam_vit_b  sam_vit_l    aji  100   0.000631  8.512050e-06   \n",
       "4      sam_vit_b  sam_vit_h    aji  100  -0.000293  2.345791e-03   \n",
       "\n",
       "            w_p        t_p_bh  t_p_sig_bh        w_p_bh  w_p_sig_bh  \n",
       "0  3.896560e-18  1.166256e-21        True  7.793120e-18        True  \n",
       "1  3.896560e-18  1.307240e-20        True  7.793120e-18        True  \n",
       "2  3.896560e-18  1.166256e-21        True  7.793120e-18        True  \n",
       "3  7.459505e-06  1.021446e-05        True  8.951406e-06        True  \n",
       "4  1.037475e-03  2.345791e-03        True  1.037475e-03        True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pairwise statistical analysis with BH correction\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "metrics = [\"pq\", \"f1_object\", \"aji\", \"dice_bin\"]\n",
    "models = res_df[\"model\"].unique().tolist()\n",
    "\n",
    "pairwise_rows = []\n",
    "for m1, m2 in combinations(models, 2):\n",
    "    df1 = res_df[res_df.model == m1].set_index([\"tissue\", \"image_id\"])  # align by image\n",
    "    df2 = res_df[res_df.model == m2].set_index([\"tissue\", \"image_id\"])  # same ids\n",
    "    common_idx = df1.index.intersection(df2.index)\n",
    "    if len(common_idx) < 5:\n",
    "        continue\n",
    "    for metric in metrics:\n",
    "        x = df1.loc[common_idx, metric].values\n",
    "        y = df2.loc[common_idx, metric].values\n",
    "        if len(x) != len(y) or len(x) < 5:\n",
    "            continue\n",
    "        # Paired tests\n",
    "        t_stat, t_p = ttest_rel(x, y, nan_policy='omit')\n",
    "        try:\n",
    "            w_stat, w_p = wilcoxon(x, y)\n",
    "        except Exception:\n",
    "            w_stat, w_p = np.nan, np.nan\n",
    "        diff = np.nanmean(x - y)\n",
    "        pairwise_rows.append({\n",
    "            \"model1\": m1,\n",
    "            \"model2\": m2,\n",
    "            \"metric\": metric,\n",
    "            \"n\": int(len(x)),\n",
    "            \"mean_diff\": float(diff),\n",
    "            \"t_p\": float(t_p) if np.isfinite(t_p) else 1.0,\n",
    "            \"w_p\": float(w_p) if np.isfinite(w_p) else 1.0,\n",
    "        })\n",
    "\n",
    "pairwise_df = pd.DataFrame(pairwise_rows)\n",
    "if not pairwise_df.empty:\n",
    "    # BH correction per metric separately\n",
    "    corrected = []\n",
    "    for metric, g in pairwise_df.groupby(\"metric\"):\n",
    "        for col in [\"t_p\", \"w_p\"]:\n",
    "            rej, p_bh, _, _ = multipletests(g[col].values, method='fdr_bh')\n",
    "            g[col+\"_bh\"] = p_bh\n",
    "            g[col+\"_sig_bh\"] = rej\n",
    "        corrected.append(g)\n",
    "    pairwise_df = pd.concat(corrected, ignore_index=True)\n",
    "\n",
    "pairwise_csv = CSV_DIR / \"pairwise_stats_bh.csv\"\n",
    "pairwise_df.to_csv(pairwise_csv, index=False)\n",
    "print(\"Saved:\", pairwise_csv)\n",
    "\n",
    "pairwise_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspace/HistoPathologyResearch/reports/rq1/figures/pq_by_model.png\n",
      "Saved: /workspace/HistoPathologyResearch/reports/rq1/figures/f1_by_model.png\n"
     ]
    }
   ],
   "source": [
    "# Plots\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=res_df, x=\"model\", y=\"pq\")\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.title(\"PQ by model\")\n",
    "plt.tight_layout()\n",
    "fig_path1 = FIG_DIR / \"pq_by_model.png\"\n",
    "plt.savefig(fig_path1, dpi=200)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=res_df, x=\"model\", y=\"f1_object\")\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.title(\"Object F1 by model\")\n",
    "plt.tight_layout()\n",
    "fig_path2 = FIG_DIR / \"f1_by_model.png\"\n",
    "plt.savefig(fig_path2, dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved:\", fig_path1)\n",
    "print(\"Saved:\", fig_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspace/HistoPathologyResearch/reports/rq1/tables/per_tissue_wilcoxon_bh.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tissue</th>\n",
       "      <th>sam</th>\n",
       "      <th>established</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>wilcoxon_p</th>\n",
       "      <th>wilcoxon_p_bh</th>\n",
       "      <th>sig_bh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tissue, sam, established, metric, n, mean_diff, wilcoxon_p, wilcoxon_p_bh, sig_bh]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per-tissue paired Wilcoxon tests (BH corrected)\n",
    "from itertools import product\n",
    "\n",
    "metrics_primary = [\"pq\", \"f1_object\"]\n",
    "sam_models = [m for m in res_df.model.unique() if m.startswith(\"sam\")]\n",
    "established = [m for m in [\"hovernet\", \"cellvit\", \"lkcell\"] if m in res_df.model.unique()]\n",
    "\n",
    "rows = []\n",
    "for tissue in sorted(res_df.tissue.unique()):\n",
    "    df_t = res_df[res_df.tissue == tissue].set_index([\"tissue\", \"image_id\"])  # align pairs\n",
    "    for sam, est, metric in product(sam_models, established, metrics_primary):\n",
    "        a = df_t[df_t.model == sam][metric]\n",
    "        b = df_t[df_t.model == est][metric]\n",
    "        idx = a.index.intersection(b.index)\n",
    "        if len(idx) < 5:\n",
    "            continue\n",
    "        x, y = a.loc[idx].values, b.loc[idx].values\n",
    "        try:\n",
    "            stat, p = wilcoxon(x, y)\n",
    "        except Exception:\n",
    "            p = 1.0\n",
    "        rows.append({\n",
    "            \"tissue\": tissue,\n",
    "            \"sam\": sam,\n",
    "            \"established\": est,\n",
    "            \"metric\": metric,\n",
    "            \"n\": int(len(idx)),\n",
    "            \"mean_diff\": float(np.nanmean(x - y)),\n",
    "            \"wilcoxon_p\": float(p)\n",
    "        })\n",
    "\n",
    "tissue_df = pd.DataFrame(rows)\n",
    "if not tissue_df.empty:\n",
    "    outs = []\n",
    "    for metric, g in tissue_df.groupby(\"metric\"):\n",
    "        rej, p_bh, _, _ = multipletests(g[\"wilcoxon_p\"].values, method=\"fdr_bh\")\n",
    "        g = g.assign(wilcoxon_p_bh=p_bh, sig_bh=rej)\n",
    "        outs.append(g)\n",
    "    tissue_df_bh = pd.concat(outs, ignore_index=True)\n",
    "else:\n",
    "    tissue_df_bh = pd.DataFrame(columns=[\"tissue\",\"sam\",\"established\",\"metric\",\"n\",\"mean_diff\",\"wilcoxon_p\",\"wilcoxon_p_bh\",\"sig_bh\"])\n",
    "\n",
    "per_tissue_csv = CSV_DIR / \"per_tissue_wilcoxon_bh.csv\"\n",
    "tissue_df_bh.to_csv(per_tissue_csv, index=False)\n",
    "print(\"Saved:\", per_tissue_csv)\n",
    "\n",
    "tissue_df_bh.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspace/HistoPathologyResearch/reports/rq1/RQ1_SAM_Variants_Report.html\n"
     ]
    }
   ],
   "source": [
    "# HTML report (with per-tissue section)\n",
    "from datetime import datetime\n",
    "\n",
    "report_html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html><head><meta charset='utf-8'><title>RQ1 - SAM Variants vs Baselines</title></head>\n",
    "<body style='font-family:Segoe UI,Arial,sans-serif; margin:40px;'>\n",
    "<h1>RQ1: SAM Variants vs Established Models on PanNuke</h1>\n",
    "<p><em>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</em></p>\n",
    "<h2>Per-image metrics</h2>\n",
    "<p>Saved CSV: {csv_path.name}</p>\n",
    "<h2>Summary (by model)</h2>\n",
    "{summary.to_html()}\n",
    "<h2>Pairwise statistics (BH corrected)</h2>\n",
    "{pairwise_df.head(50).to_html(index=False) if 'pairwise_df' in globals() and not pairwise_df.empty else '<p>No pairwise results.</p>'}\n",
    "<h2>Per-tissue paired Wilcoxon (BH corrected)</h2>\n",
    "{tissue_df_bh.head(100).to_html(index=False) if 'tissue_df_bh' in globals() and not tissue_df_bh.empty else '<p>No per-tissue results.</p>'}\n",
    "<h2>Figures</h2>\n",
    "<ul>\n",
    "  <li>{fig_path1.name}</li>\n",
    "  <li>{fig_path2.name}</li>\n",
    "</ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "html_path = REPORTS_DIR / \"RQ1_SAM_Variants_Report.html\"\n",
    "html_path.write_text(report_html, encoding='utf-8')\n",
    "print(\"Saved:\", html_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspace/HistoPathologyResearch/reports/rq1/RQ1_SAM_Variants_Report.html\n"
     ]
    }
   ],
   "source": [
    "# HTML report\n",
    "from datetime import datetime\n",
    "\n",
    "report_html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html><head><meta charset='utf-8'><title>RQ1 - SAM Variants vs Baselines</title></head>\n",
    "<body style='font-family:Segoe UI,Arial,sans-serif; margin:40px;'>\n",
    "<h1>RQ1: SAM Variants vs Established Models on PanNuke</h1>\n",
    "<p><em>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</em></p>\n",
    "<h2>Per-image metrics</h2>\n",
    "<p>Saved CSV: {csv_path.name}</p>\n",
    "<h2>Summary (by model)</h2>\n",
    "{summary.to_html()}\n",
    "<h2>Pairwise statistics (BH corrected)</h2>\n",
    "{pairwise_df.head(50).to_html(index=False)}\n",
    "<h2>Figures</h2>\n",
    "<ul>\n",
    "  <li>{fig_path1.name}</li>\n",
    "  <li>{fig_path2.name}</li>\n",
    "</ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "html_path = REPORTS_DIR / \"RQ1_SAM_Variants_Report.html\"\n",
    "html_path.write_text(report_html, encoding='utf-8')\n",
    "print(\"Saved:\", html_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
